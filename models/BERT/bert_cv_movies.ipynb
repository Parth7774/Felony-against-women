{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vkr-bw_b1JQX"
   },
   "source": [
    "# Hate speech classification by k-fold cross validation on movies dataset\n",
    "\n",
    "\n",
    "\n",
    "The class labels depict the following:\n",
    "\n",
    "0: Normal speech, \n",
    "1: Offensive speech\n",
    "2: Hate speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To work with this, the following folder paths needs to be created in the directory of this notebook:\n",
    "classification_reports/   : This will contain all the classification reports generated by the model\n",
    "\n",
    "movies/       : contains all_movies.csv file\n",
    "\n",
    "movies/for_training/:    contains 6 movies used for cross validation training and testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cqyGp3sQg0h",
    "outputId": "aee25fd1-fdcf-4611-a59b-29d2c111f329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting transformers==2.6.0\n",
      "  Using cached transformers-2.6.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from transformers==2.6.0) (2.2.3)\n",
      "Collecting tokenizers==0.5.2 (from transformers==2.6.0)\n",
      "  Using cached tokenizers-0.5.2.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting boto3 (from transformers==2.6.0)\n",
      "  Downloading boto3-1.37.11-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting filelock (from transformers==2.6.0)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting requests (from transformers==2.6.0)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.27 (from transformers==2.6.0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==2.6.0)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting sentencepiece (from transformers==2.6.0)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Collecting sacremoses (from transformers==2.6.0)\n",
      "  Using cached sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting colorama (from tqdm>=4.27->transformers==2.6.0)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting botocore<1.38.0,>=1.37.11 (from boto3->transformers==2.6.0)\n",
      "  Downloading botocore-1.37.11-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->transformers==2.6.0)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->transformers==2.6.0)\n",
      "  Downloading s3transfer-0.11.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers==2.6.0)\n",
      "  Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers==2.6.0)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers==2.6.0)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers==2.6.0)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting click (from sacremoses->transformers==2.6.0)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from sacremoses->transformers==2.6.0) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from botocore<1.38.0,>=1.37.11->boto3->transformers==2.6.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.11->boto3->transformers==2.6.0) (1.17.0)\n",
      "Using cached transformers-2.6.0-py3-none-any.whl (540 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading boto3-1.37.11-py3-none-any.whl (139 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Downloading botocore-1.37.11-py3-none-any.whl (13.4 MB)\n",
      "   ---------------------------------------- 13.4/13.4 MB 773.9 kB/s eta 0:00:00\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.11.4-py3-none-any.whl (84 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [44 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "      copying tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "      copying tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "      copying tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "      copying tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "      copying tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "      copying tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "      copying tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "      creating build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-312\\tokenizers\\implementations\n",
      "      copying tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\n",
      "      copying tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\models\n",
      "      copying tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\decoders\n",
      "      copying tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\normalizers\n",
      "      copying tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\pre_tokenizers\n",
      "      copying tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\processors\n",
      "      copying tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-312\\tokenizers\\trainers\n",
      "      running build_ext\n",
      "      running build_rust\n",
      "      error: can't find Rust compiler\n",
      "      \n",
      "      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "      \n",
      "      To update pip, run:\n",
      "      \n",
      "          pip install --upgrade pip\n",
      "      \n",
      "      and then retry package installation.\n",
      "      \n",
      "      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: C:\\Python312\\python.exe -m pip install --upgrade pip\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers==2.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlibNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "     ---------------------------------------- 8.1/8.1 MB 1.1 MB/s eta 0:00:00\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.56.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.2.3)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (3.0.9)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "     ------------------------------------ 218.6/218.6 kB 633.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "     -------------------------------------- 71.9/71.9 kB 978.5 kB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading tensorflow-2.10.0-cp310-cp310-win_amd64.whl (455.9 MB)\n",
      "     ---------------------------------      398.5/455.9 MB 1.6 MB/s eta 0:00:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 435, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 516, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py\", line 465, in read\n",
      "    s = self.fp.read(amt)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1274, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py\", line 1130, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 167, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 247, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 369, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 481, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 348, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 297, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 231, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 308, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 438, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 483, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 165, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 106, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 573, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 509, in read\n",
      "    with self._error_catcher():\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 440, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp310-cp310-win_amd64.whl (375.7 MB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Using cached ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (63.2.0)\n",
      "Collecting h5py>=3.11.0\n",
      "  Using cached h5py-3.13.0-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Collecting keras>=3.5.0\n",
      "  Using cached keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.14.1-cp310-cp310-win_amd64.whl (296 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.13.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: optree, ml-dtypes, mdurl, MarkupSafe, markdown, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, astunparse, absl-py, werkzeug, requests, markdown-it-py, tensorboard, rich, keras, tensorflow\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] The process cannot access the file because it is being used by another process: 'c:\\\\Users\\\\hp\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\layers\\\\reshaping\\\\flatten.py'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3YwUM7V6OewJ"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pywrap_tensorflow' from 'tensorflow.python' (c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\__init__.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m _os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mENABLE_RUNTIME_UPTIME_TELEMETRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Do not remove this line; See https://github.com/tensorflow/tensorflow/issues/42596\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasLazyLoader \u001b[38;5;28;01mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pywrap_tensorflow' from 'tensorflow.python' (c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\__init__.py)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp310-cp310-win_amd64.whl (375.7 MB)\n",
      "     -------------------------------------- 375.7/375.7 MB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Using cached h5py-3.13.0-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Collecting tensorboard~=2.19.0\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 6.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (63.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "     ---------------------------------------- 4.3/4.3 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1\n",
      "  Downloading ml_dtypes-0.5.1-cp310-cp310-win_amd64.whl (209 kB)\n",
      "     -------------------------------------- 209.7/209.7 kB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.9.0-py3-none-any.whl (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Collecting optree\n",
      "  Downloading optree-0.14.1-cp310-cp310-win_amd64.whl (296 kB)\n",
      "     -------------------------------------- 296.5/296.5 kB 3.7 MB/s eta 0:00:00\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Requirement already satisfied: namex in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.13.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: optree, ml-dtypes, mdurl, MarkupSafe, markdown, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, certifi, astunparse, absl-py, werkzeug, requests, markdown-it-py, tensorboard, rich, keras, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 keras-3.9.0 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 optree-0.14.1 requests-2.32.3 rich-13.9.4 tensorboard-2.19.0 tensorflow-2.19.0 werkzeug-3.1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213,
     "referenced_widgets": [
      "b61e58ec33e34a57bb354bbe4c4d1e13",
      "699ecfecf9c64a59b4fb1f30215f843a",
      "de3bab8399f54373af8c5730eca6c2ec",
      "11f1a34076c74633b66d57742ac5bc98",
      "d5b661f5278c420f8fb90395954fe56c",
      "0c7b27f9468d4c489aab7de650187c78",
      "b3b0977670c346588362112ac9449c1d",
      "6cc29a0852e74d5ba923bf30b79983ea",
      "cd0ac0d3cc56424a877eea10f9026662",
      "5a4a1a1fea8347369f180c549e26a308",
      "032bcb93fe6948528b3633fda62a4710",
      "376985f2bc034027919a4817338caa32",
      "c4b72967b7994131ae2e695a995ec361",
      "c92b299da5b149ec8517ddc8df4aaa15",
      "2f71f9879c66495fb4b4a322c6aac0c0",
      "bc594f230e9f4bf0b24d01d027862f6e",
      "4c4d8f38728a4c9eb377be33105da4ec",
      "61ec098d19c243c79969be89d9435583",
      "522ffd79062a44b8b65d16a26ac95c55",
      "d0565a23c1cc4955ac4e3b5a81e1fd7b",
      "ed0ece8debcd45b288320e1a8797be60",
      "c4b32aec61c047e5b7c903e1991d940c",
      "93d1f8af4a894615b404ed17091919d5",
      "a6a5a9d0cbdb4de99fd1c88497f247f3",
      "c86279a8f86e4f75ad048c4d6677fdab",
      "f3c54f46189b4aaeae6dc5a94302e395",
      "0dccce07c4024c4496d2b68b0d9077e5",
      "bb11a84b2e99436b9c9bd89e9246119c",
      "6e2363d5466f46459873c2a5b36eea1c",
      "a04bf088c25e40919d8eb14a08c0b12c",
      "ac6babb0b35c4c0898f7194d30bb56e5",
      "a53aaa4f0faf4e4d8a3aa8f1b5a47730"
     ]
    },
    "id": "SI4UAcYcOpxc",
    "outputId": "70b42db8-15d3-40f0-e727-87c65e07b07f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertForSequenceClassification\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InputExample, InputFeatures\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J1kcn3M5nEi"
   },
   "source": [
    "\n",
    "---\n",
    "### Cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccJl8pYO5yI-"
   },
   "source": [
    "#### 6-fold cross validation on movies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods to convert the data into the data required by the model for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xRSnyXKl5xol"
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples_cv(train, DATA_COLUMN, LABEL_COLUMN):\n",
    "    train_InputExamples = train.apply(\n",
    "        lambda x: InputExample(guid=None,  # Globally unique ID for bookkeeping, unused in this case\n",
    "                               text_a=x[DATA_COLUMN],\n",
    "                               text_b=None,\n",
    "                               label=x[LABEL_COLUMN]), axis=1)\n",
    "\n",
    "    return train_InputExamples\n",
    "\n",
    "\n",
    "def convert_examples_to_tf_dataset_cv(examples, tokenizer, max_length=128):\n",
    "    features = []  # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,  # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True,  # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "                                                     input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8fqcU2hAHFc_"
   },
   "outputs": [],
   "source": [
    "def train_bert(df_train, df_test):\n",
    "    # initialize model with 3 labels, for hate, offensive and normal class classification\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                            trainable=True,\n",
    "                                                            num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    train = df_train[['text', 'majority_answer']]\n",
    "    train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "\n",
    "    test = df_test[['text', 'majority_answer']]\n",
    "    test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "\n",
    "    DATA_COLUMN = 'DATA_COLUMN'\n",
    "    LABEL_COLUMN = 'LABEL_COLUMN'\n",
    "\n",
    "    train_InputExamples = convert_data_to_examples_cv(train, DATA_COLUMN, LABEL_COLUMN)\n",
    "    test_InputExamples = convert_data_to_examples_cv(test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "    train_data = convert_examples_to_tf_dataset_cv(list(train_InputExamples), tokenizer)\n",
    "    train_data = train_data.batch(32)\n",
    "\n",
    "    valid_data = convert_examples_to_tf_dataset_cv(list(test_InputExamples), tokenizer)\n",
    "    valid_data = valid_data.batch(32)\n",
    "\n",
    "    # compile and fit\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-6, epsilon=1e-08, clipnorm=1.0),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "    print('train data type',type(train_data))\n",
    "    model.fit(train_data, epochs=6, validation_data=valid_data)\n",
    "\n",
    "    test_data = convert_examples_to_tf_dataset_cv(list(test_InputExamples), tokenizer)\n",
    "    test_data = test_data.batch(32)\n",
    "\n",
    "    print('predicting')\n",
    "    preds = model.predict(test_data)\n",
    "\n",
    "    # classification\n",
    "    return classification_report(pd.DataFrame(test['LABEL_COLUMN']), np.argmax(preds[0], axis=1), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DWsFTqlHlgv3"
   },
   "outputs": [],
   "source": [
    "def load_movies_to_df(path):\n",
    "    df_movies = []\n",
    "\n",
    "    for filename in glob.glob(path + '*.csv'):\n",
    "        df_movies.append(pd.read_csv(filename))\n",
    "\n",
    "    return df_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Xz1rCrpvB2RA"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_movies \u001b[38;5;241m=\u001b[39m load_movies_to_df(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/movies/for_training/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m classification_reports \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m df_main \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n",
      "Cell \u001b[1;32mIn [11], line 4\u001b[0m, in \u001b[0;36mload_movies_to_df\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_movies_to_df\u001b[39m(path):\n\u001b[0;32m      2\u001b[0m     df_movies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mglob\u001b[49m\u001b[38;5;241m.\u001b[39mglob(path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      5\u001b[0m         df_movies\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mread_csv(filename))\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_movies\n",
      "\u001b[1;31mNameError\u001b[0m: name 'glob' is not defined"
     ]
    }
   ],
   "source": [
    "df_movies = load_movies_to_df('data/movies/for_training/')\n",
    "classification_reports = []\n",
    "df_main = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpchIXr0lciQ",
    "outputId": "1b21ce5b-279e-415e-8be6-240b63a196f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "BlacKkKlansman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data type <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    283/Unknown - 236s 767ms/step - loss: 0.6180 - accuracy: 0.8040WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "283/283 [==============================] - 253s 827ms/step - loss: 0.6180 - accuracy: 0.8040 - val_loss: 0.3662 - val_accuracy: 0.8979\n",
      "Epoch 2/6\n",
      "283/283 [==============================] - 239s 843ms/step - loss: 0.2421 - accuracy: 0.9328 - val_loss: 0.2421 - val_accuracy: 0.9337\n",
      "Epoch 3/6\n",
      "283/283 [==============================] - 239s 843ms/step - loss: 0.1516 - accuracy: 0.9592 - val_loss: 0.2204 - val_accuracy: 0.9374\n",
      "Epoch 4/6\n",
      "283/283 [==============================] - 239s 843ms/step - loss: 0.1208 - accuracy: 0.9674 - val_loss: 0.2143 - val_accuracy: 0.9386\n",
      "Epoch 5/6\n",
      "283/283 [==============================] - 239s 844ms/step - loss: 0.1030 - accuracy: 0.9722 - val_loss: 0.2172 - val_accuracy: 0.9392\n",
      "Epoch 6/6\n",
      "283/283 [==============================] - 239s 843ms/step - loss: 0.0896 - accuracy: 0.9756 - val_loss: 0.2201 - val_accuracy: 0.9404\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Test movie:  BlacKkKlansman\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9631120053655265, 'recall': 0.9822161422708618, 'f1-score': 0.9725702675245513, 'support': 1462}, '1': {'precision': 0.6382978723404256, 'recall': 0.6185567010309279, 'f1-score': 0.6282722513089005, 'support': 97}, '2': {'precision': 0.85, 'recall': 0.5930232558139535, 'f1-score': 0.6986301369863014, 'support': 86}, 'accuracy': 0.9404255319148936, 'macro avg': {'precision': 0.8171366259019841, 'recall': 0.7312653663719145, 'f1-score': 0.7664908852732512, 'support': 1645}, 'weighted avg': {'precision': 0.9380453771801952, 'recall': 0.9404255319148936, 'f1-score': 0.9379467059444859, 'support': 1645}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Pulp_Fiction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data type <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    284/Unknown - 242s 788ms/step - loss: 0.5010 - accuracy: 0.8516WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "284/284 [==============================] - 259s 846ms/step - loss: 0.5010 - accuracy: 0.8516 - val_loss: 0.2814 - val_accuracy: 0.9334\n",
      "Epoch 2/6\n",
      "284/284 [==============================] - 239s 842ms/step - loss: 0.2091 - accuracy: 0.9336 - val_loss: 0.1857 - val_accuracy: 0.9396\n",
      "Epoch 3/6\n",
      "284/284 [==============================] - 239s 841ms/step - loss: 0.1485 - accuracy: 0.9558 - val_loss: 0.1647 - val_accuracy: 0.9482\n",
      "Epoch 4/6\n",
      "284/284 [==============================] - 239s 842ms/step - loss: 0.1171 - accuracy: 0.9646 - val_loss: 0.1644 - val_accuracy: 0.9470\n",
      "Epoch 5/6\n",
      "284/284 [==============================] - 239s 841ms/step - loss: 0.0978 - accuracy: 0.9688 - val_loss: 0.1688 - val_accuracy: 0.9464\n",
      "Epoch 6/6\n",
      "284/284 [==============================] - 239s 841ms/step - loss: 0.0844 - accuracy: 0.9728 - val_loss: 0.1812 - val_accuracy: 0.9451\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Test movie:  Pulp_Fiction\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9706103993971364, 'recall': 0.9662415603900976, 'f1-score': 0.968421052631579, 'support': 1333}, '1': {'precision': 0.8302583025830258, 'recall': 0.8490566037735849, 'f1-score': 0.8395522388059701, 'support': 265}, '2': {'precision': 0.8333333333333334, 'recall': 0.8333333333333334, 'f1-score': 0.8333333333333334, 'support': 24}, 'accuracy': 0.9451294697903823, 'macro avg': {'precision': 0.8780673451044986, 'recall': 0.8828771658323387, 'f1-score': 0.8804355415902941, 'support': 1622}, 'weighted avg': {'precision': 0.9456486514062173, 'recall': 0.9451294697903823, 'f1-score': 0.9453678214805653, 'support': 1622}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "AmerricanHistoryX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data type <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    286/Unknown - 244s 787ms/step - loss: 0.5274 - accuracy: 0.8316WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "286/286 [==============================] - 261s 844ms/step - loss: 0.5274 - accuracy: 0.8316 - val_loss: 0.2838 - val_accuracy: 0.9182\n",
      "Epoch 2/6\n",
      "286/286 [==============================] - 240s 839ms/step - loss: 0.1971 - accuracy: 0.9509 - val_loss: 0.2096 - val_accuracy: 0.9425\n",
      "Epoch 3/6\n",
      "286/286 [==============================] - 240s 839ms/step - loss: 0.1391 - accuracy: 0.9600 - val_loss: 0.2066 - val_accuracy: 0.9431\n",
      "Epoch 4/6\n",
      "286/286 [==============================] - 240s 839ms/step - loss: 0.1156 - accuracy: 0.9673 - val_loss: 0.2070 - val_accuracy: 0.9450\n",
      "Epoch 5/6\n",
      "286/286 [==============================] - 240s 839ms/step - loss: 0.0988 - accuracy: 0.9731 - val_loss: 0.2259 - val_accuracy: 0.9406\n",
      "Epoch 6/6\n",
      "286/286 [==============================] - 240s 839ms/step - loss: 0.0870 - accuracy: 0.9754 - val_loss: 0.2292 - val_accuracy: 0.9406\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Test movie:  AmerricanHistoryX\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9567809239940388, 'recall': 0.9846625766871165, 'f1-score': 0.9705215419501135, 'support': 1304}, '1': {'precision': 0.8177083333333334, 'recall': 0.7584541062801933, 'f1-score': 0.786967418546366, 'support': 207}, '2': {'precision': 1.0, 'recall': 0.5740740740740741, 'f1-score': 0.7294117647058824, 'support': 54}, 'accuracy': 0.9405750798722045, 'macro avg': {'precision': 0.9248297524424575, 'recall': 0.7723969190137946, 'f1-score': 0.8289669084007874, 'support': 1565}, 'weighted avg': {'precision': 0.9398772842736272, 'recall': 0.9405750798722045, 'f1-score': 0.9379236943362067, 'support': 1565}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,Django_Unchained,South_Park\n",
      "TheWolfofWallStreet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data type <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    239/Unknown - 206s 786ms/step - loss: 0.5514 - accuracy: 0.7975WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "239/239 [==============================] - 235s 908ms/step - loss: 0.5514 - accuracy: 0.7975 - val_loss: 0.2976 - val_accuracy: 0.8077\n",
      "Epoch 2/6\n",
      "239/239 [==============================] - 216s 904ms/step - loss: 0.2562 - accuracy: 0.9005 - val_loss: 0.1250 - val_accuracy: 0.9745\n",
      "Epoch 3/6\n",
      "239/239 [==============================] - 216s 905ms/step - loss: 0.1730 - accuracy: 0.9500 - val_loss: 0.0969 - val_accuracy: 0.9739\n",
      "Epoch 4/6\n",
      "239/239 [==============================] - 216s 905ms/step - loss: 0.1400 - accuracy: 0.9572 - val_loss: 0.0931 - val_accuracy: 0.9729\n",
      "Epoch 5/6\n",
      "239/239 [==============================] - 216s 903ms/step - loss: 0.1228 - accuracy: 0.9622 - val_loss: 0.0851 - val_accuracy: 0.9709\n",
      "Epoch 6/6\n",
      "239/239 [==============================] - 216s 904ms/step - loss: 0.1049 - accuracy: 0.9672 - val_loss: 0.0906 - val_accuracy: 0.9709\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,Django_Unchained,South_Park\n",
      "Test movie:  TheWolfofWallStreet\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9787319422150883, 'recall': 0.9858528698464026, 'f1-score': 0.9822795006041081, 'support': 2474}, '1': {'precision': 0.941696113074205, 'recall': 0.9080068143100511, 'f1-score': 0.9245446660884649, 'support': 587}, '2': {'precision': 0.4, 'recall': 1.0, 'f1-score': 0.5714285714285715, 'support': 2}, 'accuracy': 0.9709435194253999, 'macro avg': {'precision': 0.7734760184297644, 'recall': 0.9646198947188179, 'f1-score': 0.8260842460403816, 'support': 3063}, 'weighted avg': {'precision': 0.9712564294530482, 'recall': 0.9709435194253999, 'f1-score': 0.9709468039932581, 'support': 3063}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,South_Park\n",
      "Django_Unchained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data type <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    280/Unknown - 239s 791ms/step - loss: 0.5958 - accuracy: 0.8244WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "280/280 [==============================] - 257s 856ms/step - loss: 0.5958 - accuracy: 0.8244 - val_loss: 0.3800 - val_accuracy: 0.8941\n",
      "Epoch 2/6\n",
      "280/280 [==============================] - 237s 847ms/step - loss: 0.2050 - accuracy: 0.9399 - val_loss: 0.1837 - val_accuracy: 0.9033\n",
      "Epoch 3/6\n",
      "280/280 [==============================] - 242s 866ms/step - loss: 0.1516 - accuracy: 0.9540 - val_loss: 0.1231 - val_accuracy: 0.9708\n",
      "Epoch 4/6\n",
      "280/280 [==============================] - 237s 847ms/step - loss: 0.1238 - accuracy: 0.9623 - val_loss: 0.1066 - val_accuracy: 0.9720\n",
      "Epoch 5/6\n",
      "280/280 [==============================] - 237s 846ms/step - loss: 0.1042 - accuracy: 0.9688 - val_loss: 0.1053 - val_accuracy: 0.9708\n",
      "Epoch 6/6\n",
      "280/280 [==============================] - 237s 847ms/step - loss: 0.0895 - accuracy: 0.9728 - val_loss: 0.1104 - val_accuracy: 0.9679\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,South_Park\n",
      "Test movie:  Django_Unchained\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9788867562380038, 'recall': 0.9864603481624759, 'f1-score': 0.9826589595375722, 'support': 1551}, '1': {'precision': 0.7222222222222222, 'recall': 0.6582278481012658, 'f1-score': 0.6887417218543045, 'support': 79}, '2': {'precision': 0.9732142857142857, 'recall': 0.9316239316239316, 'f1-score': 0.9519650655021833, 'support': 117}, 'accuracy': 0.9679450486548369, 'macro avg': {'precision': 0.8914410880581706, 'recall': 0.8587707092958912, 'f1-score': 0.8744552489646867, 'support': 1747}, 'weighted avg': {'precision': 0.9669003926212197, 'recall': 0.9679450486548369, 'f1-score': 0.9673122810148942, 'support': 1747}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained\n",
      "South_Park\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data type <class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n",
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    302/Unknown - 258s 792ms/step - loss: 0.5294 - accuracy: 0.8458WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "302/302 [==============================] - 270s 831ms/step - loss: 0.5294 - accuracy: 0.8458 - val_loss: 0.2766 - val_accuracy: 0.9178\n",
      "Epoch 2/6\n",
      "302/302 [==============================] - 248s 823ms/step - loss: 0.1879 - accuracy: 0.9378 - val_loss: 0.2238 - val_accuracy: 0.9331\n",
      "Epoch 3/6\n",
      "302/302 [==============================] - 248s 822ms/step - loss: 0.1391 - accuracy: 0.9606 - val_loss: 0.2204 - val_accuracy: 0.9312\n",
      "Epoch 4/6\n",
      "302/302 [==============================] - 248s 822ms/step - loss: 0.1128 - accuracy: 0.9658 - val_loss: 0.2216 - val_accuracy: 0.9340\n",
      "Epoch 5/6\n",
      "302/302 [==============================] - 248s 820ms/step - loss: 0.0944 - accuracy: 0.9718 - val_loss: 0.2148 - val_accuracy: 0.9379\n",
      "Epoch 6/6\n",
      "302/302 [==============================] - 248s 821ms/step - loss: 0.0783 - accuracy: 0.9770 - val_loss: 0.2427 - val_accuracy: 0.9350\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained\n",
      "Test movie:  South_Park\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9497267759562842, 'recall': 0.9764044943820225, 'f1-score': 0.9628808864265929, 'support': 890}, '1': {'precision': 0.8359375, 'recall': 0.7379310344827587, 'f1-score': 0.783882783882784, 'support': 145}, '2': {'precision': 0.6666666666666666, 'recall': 0.18181818181818182, 'f1-score': 0.28571428571428575, 'support': 11}, 'accuracy': 0.9349904397705545, 'macro avg': {'precision': 0.8174436475409835, 'recall': 0.632051236894321, 'f1-score': 0.6774926520078876, 'support': 1046}, 'weighted avg': {'precision': 0.9309761964000252, 'recall': 0.9349904397705545, 'f1-score': 0.9309463190492623, 'support': 1046}}\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# perform cross folding\n",
    "for i in range(len(df_movies)):\n",
    "    df_train = pd.concat(df_movies[0:i] + df_movies[i + 1:])\n",
    "    df_test = df_movies[i]\n",
    "\n",
    "    train_movies = df_train['movie_name'].unique()\n",
    "    test_movie = df_test['movie_name'].unique()\n",
    "    print(','.join(train_movies))\n",
    "    print(test_movie[0])\n",
    "\n",
    "    report = train_bert(df_train, df_test)\n",
    "    classification_reports.append(report)\n",
    "    \n",
    "    print('Train movies: ', str(','.join(train_movies)))\n",
    "    print('Test movie: ', str(test_movie[0]))\n",
    "    print('Classification report: \\n', classification_reports[i])\n",
    "    print('------------------------------------------------')\n",
    "\n",
    "    df_cr = pd.DataFrame(classification_reports[i]).transpose()\n",
    "    df_cr['movie_train'] =  str(','.join(train_movies))\n",
    "    df_cr['movie_test'] = str(test_movie[0])\n",
    "    df_cr.to_csv('classification_reports/'+'bert_cv_testmovie_'+str(test_movie[0])+'.csv')\n",
    "    df_main = df_main.append(df_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LyfPoHfVB63k"
   },
   "outputs": [],
   "source": [
    "df_main.to_csv('classification_reports/bert_crossvalid_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9c-yeiBHfGG",
    "outputId": "468178dc-04e5-4d4d-a08e-109f144ac458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  ...           movie_test\n",
      "0              0.963112  ...       BlacKkKlansman\n",
      "1              0.638298  ...       BlacKkKlansman\n",
      "2              0.850000  ...       BlacKkKlansman\n",
      "accuracy       0.940426  ...       BlacKkKlansman\n",
      "macro avg      0.817137  ...       BlacKkKlansman\n",
      "weighted avg   0.938045  ...       BlacKkKlansman\n",
      "0              0.970610  ...         Pulp_Fiction\n",
      "1              0.830258  ...         Pulp_Fiction\n",
      "2              0.833333  ...         Pulp_Fiction\n",
      "accuracy       0.945129  ...         Pulp_Fiction\n",
      "macro avg      0.878067  ...         Pulp_Fiction\n",
      "weighted avg   0.945649  ...         Pulp_Fiction\n",
      "0              0.956781  ...    AmerricanHistoryX\n",
      "1              0.817708  ...    AmerricanHistoryX\n",
      "2              1.000000  ...    AmerricanHistoryX\n",
      "accuracy       0.940575  ...    AmerricanHistoryX\n",
      "macro avg      0.924830  ...    AmerricanHistoryX\n",
      "weighted avg   0.939877  ...    AmerricanHistoryX\n",
      "0              0.978732  ...  TheWolfofWallStreet\n",
      "1              0.941696  ...  TheWolfofWallStreet\n",
      "2              0.400000  ...  TheWolfofWallStreet\n",
      "accuracy       0.970944  ...  TheWolfofWallStreet\n",
      "macro avg      0.773476  ...  TheWolfofWallStreet\n",
      "weighted avg   0.971256  ...  TheWolfofWallStreet\n",
      "0              0.978887  ...     Django_Unchained\n",
      "1              0.722222  ...     Django_Unchained\n",
      "2              0.973214  ...     Django_Unchained\n",
      "accuracy       0.967945  ...     Django_Unchained\n",
      "macro avg      0.891441  ...     Django_Unchained\n",
      "weighted avg   0.966900  ...     Django_Unchained\n",
      "0              0.949727  ...           South_Park\n",
      "1              0.835938  ...           South_Park\n",
      "2              0.666667  ...           South_Park\n",
      "accuracy       0.934990  ...           South_Park\n",
      "macro avg      0.817444  ...           South_Park\n",
      "weighted avg   0.930976  ...           South_Park\n",
      "\n",
      "[36 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    " print(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iD3D9odZB7de",
    "outputId": "89dc5eb0-87c9-4e5a-b57e-38cedf0c52e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classification_reports[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "68L-CNl6GGg8",
    "outputId": "3dbacce7-0569-49ca-861b-c943455b37a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>movie_train</th>\n",
       "      <th>movie_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963112</td>\n",
       "      <td>0.982216</td>\n",
       "      <td>0.972570</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.628272</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.817137</td>\n",
       "      <td>0.731265</td>\n",
       "      <td>0.766491</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision  ...      movie_test\n",
       "0           0.963112  ...  BlacKkKlansman\n",
       "1           0.638298  ...  BlacKkKlansman\n",
       "2           0.850000  ...  BlacKkKlansman\n",
       "accuracy    0.940426  ...  BlacKkKlansman\n",
       "macro avg   0.817137  ...  BlacKkKlansman\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "NRGObHolGHHF"
   },
   "outputs": [],
   "source": [
    "def get_precision_recall_f1(category, result_df):\n",
    "    precision = result_df[result_df.label==category].precision.mean()\n",
    "    recall = result_df[result_df.label==category].recall.mean()\n",
    "    f1 = result_df[result_df.label==category]['f1-score'].mean()\n",
    "    \n",
    "    return {'label': category, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vj_ZEFYdRdF4"
   },
   "outputs": [],
   "source": [
    "df_cv= pd.read_csv('classification_reports/bert_crossvalid_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUdxiuhqHcJx",
    "outputId": "3d84fcc2-d3aa-4d00-c15d-62f52c2fbae6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classification_reports[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "tuiVb3fUHcJy",
    "outputId": "b68aca66-e1e1-47ec-f417-8b2dde6b33de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>movie_train</th>\n",
       "      <th>movie_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.963112</td>\n",
       "      <td>0.982216</td>\n",
       "      <td>0.972570</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.628272</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.817137</td>\n",
       "      <td>0.731265</td>\n",
       "      <td>0.766491</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision  ...      movie_test\n",
       "0           0.963112  ...  BlacKkKlansman\n",
       "1           0.638298  ...  BlacKkKlansman\n",
       "2           0.850000  ...  BlacKkKlansman\n",
       "accuracy    0.940426  ...  BlacKkKlansman\n",
       "macro avg   0.817137  ...  BlacKkKlansman\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "dRL1UIIsHcJz"
   },
   "outputs": [],
   "source": [
    "def get_precision_recall_f1(category, result_df):\n",
    "    precision = result_df[result_df.label==category].precision.mean()\n",
    "    recall = result_df[result_df.label==category].recall.mean()\n",
    "    f1 = result_df[result_df.label==category]['f1-score'].mean()\n",
    "    \n",
    "    return {'label': category, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "PVRT0b1thTtB"
   },
   "outputs": [],
   "source": [
    "df_cv= pd.read_csv('classification_reports/bert_crossvalid_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "SnXkEFJlmfSU",
    "outputId": "8505fc77-294d-47f6-e5e6-5b50b4068373"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>movie_train</th>\n",
       "      <th>movie_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.963112</td>\n",
       "      <td>0.982216</td>\n",
       "      <td>0.972570</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.628272</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>0.940426</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.817137</td>\n",
       "      <td>0.731265</td>\n",
       "      <td>0.766491</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  ...      movie_test\n",
       "0          0  ...  BlacKkKlansman\n",
       "1          1  ...  BlacKkKlansman\n",
       "2          2  ...  BlacKkKlansman\n",
       "3   accuracy  ...  BlacKkKlansman\n",
       "4  macro avg  ...  BlacKkKlansman\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv = df_cv.rename(columns={'Unnamed: 0': 'label', 'b': 'Y'})\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "V81usTykmsnl"
   },
   "outputs": [],
   "source": [
    "normal_dict = get_precision_recall_f1('0', df_cv)\n",
    "offensive_dict = get_precision_recall_f1('1',df_cv)\n",
    "hate_dict = get_precision_recall_f1('2',df_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregated classification results for all 6 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "9xnoFFrOmgu1",
    "outputId": "76b36a6e-56ff-49d6-afeb-2793df164ad3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.966308</td>\n",
       "      <td>0.980306</td>\n",
       "      <td>0.973222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.797687</td>\n",
       "      <td>0.755039</td>\n",
       "      <td>0.775327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.787202</td>\n",
       "      <td>0.685645</td>\n",
       "      <td>0.678414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  precision    recall        f1\n",
       "0     0   0.966308  0.980306  0.973222\n",
       "1     1   0.797687  0.755039  0.775327\n",
       "2     2   0.787202  0.685645  0.678414"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame([normal_dict, offensive_dict, hate_dict])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLHfd4BFnloL",
    "outputId": "b0df1c6c-2066-48d4-f897-8fbcdf26e439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9631120053655265, 'recall': 0.9822161422708618, 'f1-score': 0.9725702675245513, 'support': 1462}, '1': {'precision': 0.6382978723404256, 'recall': 0.6185567010309279, 'f1-score': 0.6282722513089005, 'support': 97}, '2': {'precision': 0.85, 'recall': 0.5930232558139535, 'f1-score': 0.6986301369863014, 'support': 86}, 'accuracy': 0.9404255319148936, 'macro avg': {'precision': 0.8171366259019841, 'recall': 0.7312653663719145, 'f1-score': 0.7664908852732512, 'support': 1645}, 'weighted avg': {'precision': 0.9380453771801952, 'recall': 0.9404255319148936, 'f1-score': 0.9379467059444859, 'support': 1645}}\n",
      "{'0': {'precision': 0.9706103993971364, 'recall': 0.9662415603900976, 'f1-score': 0.968421052631579, 'support': 1333}, '1': {'precision': 0.8302583025830258, 'recall': 0.8490566037735849, 'f1-score': 0.8395522388059701, 'support': 265}, '2': {'precision': 0.8333333333333334, 'recall': 0.8333333333333334, 'f1-score': 0.8333333333333334, 'support': 24}, 'accuracy': 0.9451294697903823, 'macro avg': {'precision': 0.8780673451044986, 'recall': 0.8828771658323387, 'f1-score': 0.8804355415902941, 'support': 1622}, 'weighted avg': {'precision': 0.9456486514062173, 'recall': 0.9451294697903823, 'f1-score': 0.9453678214805653, 'support': 1622}}\n",
      "{'0': {'precision': 0.9567809239940388, 'recall': 0.9846625766871165, 'f1-score': 0.9705215419501135, 'support': 1304}, '1': {'precision': 0.8177083333333334, 'recall': 0.7584541062801933, 'f1-score': 0.786967418546366, 'support': 207}, '2': {'precision': 1.0, 'recall': 0.5740740740740741, 'f1-score': 0.7294117647058824, 'support': 54}, 'accuracy': 0.9405750798722045, 'macro avg': {'precision': 0.9248297524424575, 'recall': 0.7723969190137946, 'f1-score': 0.8289669084007874, 'support': 1565}, 'weighted avg': {'precision': 0.9398772842736272, 'recall': 0.9405750798722045, 'f1-score': 0.9379236943362067, 'support': 1565}}\n",
      "{'0': {'precision': 0.9787319422150883, 'recall': 0.9858528698464026, 'f1-score': 0.9822795006041081, 'support': 2474}, '1': {'precision': 0.941696113074205, 'recall': 0.9080068143100511, 'f1-score': 0.9245446660884649, 'support': 587}, '2': {'precision': 0.4, 'recall': 1.0, 'f1-score': 0.5714285714285715, 'support': 2}, 'accuracy': 0.9709435194253999, 'macro avg': {'precision': 0.7734760184297644, 'recall': 0.9646198947188179, 'f1-score': 0.8260842460403816, 'support': 3063}, 'weighted avg': {'precision': 0.9712564294530482, 'recall': 0.9709435194253999, 'f1-score': 0.9709468039932581, 'support': 3063}}\n",
      "{'0': {'precision': 0.9788867562380038, 'recall': 0.9864603481624759, 'f1-score': 0.9826589595375722, 'support': 1551}, '1': {'precision': 0.7222222222222222, 'recall': 0.6582278481012658, 'f1-score': 0.6887417218543045, 'support': 79}, '2': {'precision': 0.9732142857142857, 'recall': 0.9316239316239316, 'f1-score': 0.9519650655021833, 'support': 117}, 'accuracy': 0.9679450486548369, 'macro avg': {'precision': 0.8914410880581706, 'recall': 0.8587707092958912, 'f1-score': 0.8744552489646867, 'support': 1747}, 'weighted avg': {'precision': 0.9669003926212197, 'recall': 0.9679450486548369, 'f1-score': 0.9673122810148942, 'support': 1747}}\n",
      "{'0': {'precision': 0.9497267759562842, 'recall': 0.9764044943820225, 'f1-score': 0.9628808864265929, 'support': 890}, '1': {'precision': 0.8359375, 'recall': 0.7379310344827587, 'f1-score': 0.783882783882784, 'support': 145}, '2': {'precision': 0.6666666666666666, 'recall': 0.18181818181818182, 'f1-score': 0.28571428571428575, 'support': 11}, 'accuracy': 0.9349904397705545, 'macro avg': {'precision': 0.8174436475409835, 'recall': 0.632051236894321, 'f1-score': 0.6774926520078876, 'support': 1046}, 'weighted avg': {'precision': 0.9309761964000252, 'recall': 0.9349904397705545, 'f1-score': 0.9309463190492623, 'support': 1046}}\n"
     ]
    }
   ],
   "source": [
    "for cr in classification_reports:\n",
    "  print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bZEsT4VuKY1a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_cv_movies.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "032bcb93fe6948528b3633fda62a4710": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c92b299da5b149ec8517ddc8df4aaa15",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4b72967b7994131ae2e695a995ec361",
      "value": 28
     }
    },
    "0c7b27f9468d4c489aab7de650187c78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dccce07c4024c4496d2b68b0d9077e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a04bf088c25e40919d8eb14a08c0b12c",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6e2363d5466f46459873c2a5b36eea1c",
      "value": 570
     }
    },
    "11f1a34076c74633b66d57742ac5bc98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cc29a0852e74d5ba923bf30b79983ea",
      "placeholder": "​",
      "style": "IPY_MODEL_b3b0977670c346588362112ac9449c1d",
      "value": " 232k/232k [00:02&lt;00:00, 80.3kB/s]"
     }
    },
    "2f71f9879c66495fb4b4a322c6aac0c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "376985f2bc034027919a4817338caa32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc594f230e9f4bf0b24d01d027862f6e",
      "placeholder": "​",
      "style": "IPY_MODEL_2f71f9879c66495fb4b4a322c6aac0c0",
      "value": " 28.0/28.0 [00:01&lt;00:00, 19.9B/s]"
     }
    },
    "4c4d8f38728a4c9eb377be33105da4ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_522ffd79062a44b8b65d16a26ac95c55",
       "IPY_MODEL_d0565a23c1cc4955ac4e3b5a81e1fd7b"
      ],
      "layout": "IPY_MODEL_61ec098d19c243c79969be89d9435583"
     }
    },
    "522ffd79062a44b8b65d16a26ac95c55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4b32aec61c047e5b7c903e1991d940c",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ed0ece8debcd45b288320e1a8797be60",
      "value": 466062
     }
    },
    "5a4a1a1fea8347369f180c549e26a308": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61ec098d19c243c79969be89d9435583": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "699ecfecf9c64a59b4fb1f30215f843a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cc29a0852e74d5ba923bf30b79983ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e2363d5466f46459873c2a5b36eea1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "93d1f8af4a894615b404ed17091919d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a04bf088c25e40919d8eb14a08c0b12c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a53aaa4f0faf4e4d8a3aa8f1b5a47730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6a5a9d0cbdb4de99fd1c88497f247f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ac6babb0b35c4c0898f7194d30bb56e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3b0977670c346588362112ac9449c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b61e58ec33e34a57bb354bbe4c4d1e13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de3bab8399f54373af8c5730eca6c2ec",
       "IPY_MODEL_11f1a34076c74633b66d57742ac5bc98"
      ],
      "layout": "IPY_MODEL_699ecfecf9c64a59b4fb1f30215f843a"
     }
    },
    "bb11a84b2e99436b9c9bd89e9246119c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a53aaa4f0faf4e4d8a3aa8f1b5a47730",
      "placeholder": "​",
      "style": "IPY_MODEL_ac6babb0b35c4c0898f7194d30bb56e5",
      "value": " 570/570 [00:00&lt;00:00, 8.64kB/s]"
     }
    },
    "bc594f230e9f4bf0b24d01d027862f6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b32aec61c047e5b7c903e1991d940c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b72967b7994131ae2e695a995ec361": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c86279a8f86e4f75ad048c4d6677fdab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0dccce07c4024c4496d2b68b0d9077e5",
       "IPY_MODEL_bb11a84b2e99436b9c9bd89e9246119c"
      ],
      "layout": "IPY_MODEL_f3c54f46189b4aaeae6dc5a94302e395"
     }
    },
    "c92b299da5b149ec8517ddc8df4aaa15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd0ac0d3cc56424a877eea10f9026662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_032bcb93fe6948528b3633fda62a4710",
       "IPY_MODEL_376985f2bc034027919a4817338caa32"
      ],
      "layout": "IPY_MODEL_5a4a1a1fea8347369f180c549e26a308"
     }
    },
    "d0565a23c1cc4955ac4e3b5a81e1fd7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6a5a9d0cbdb4de99fd1c88497f247f3",
      "placeholder": "​",
      "style": "IPY_MODEL_93d1f8af4a894615b404ed17091919d5",
      "value": " 466k/466k [00:00&lt;00:00, 3.08MB/s]"
     }
    },
    "d5b661f5278c420f8fb90395954fe56c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "de3bab8399f54373af8c5730eca6c2ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c7b27f9468d4c489aab7de650187c78",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5b661f5278c420f8fb90395954fe56c",
      "value": 231508
     }
    },
    "ed0ece8debcd45b288320e1a8797be60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "f3c54f46189b4aaeae6dc5a94302e395": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
