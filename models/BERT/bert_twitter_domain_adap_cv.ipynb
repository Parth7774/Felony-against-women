{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHHxWxcC1zvl"
   },
   "source": [
    "# Hate speech classification using Twitter dataset\n",
    "\n",
    "Consists of: in-domain results and domain adaptation on movies dataset results\n",
    "\n",
    "The class labels depict the following:\n",
    "\n",
    "0: Normal speech, \n",
    "1: Offensive speech\n",
    "2: Hate speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To work with this, the following folder paths needs to be created in the directory of this notebook:\n",
    "\n",
    "classification_reports/   : This will contain all the classification reports generated by the model\n",
    "\n",
    "data/         : Contains twitter.csv annotation file\n",
    "\n",
    "movies/       : contains all_movies.csv file\n",
    "\n",
    "movies/for_training/:    contains 6 movies used for cross validation training and testing\n",
    "\n",
    "training_checkpoints/in_domain/twitter/cp_twitter.ckpt  : for storing the weights of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsvBIx41liLy",
    "outputId": "b0d440ee-7b6b-4f08-e3c9-3a554b0548ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 7.5 MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 46.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 23.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 76.4 MB/s \n",
      "\u001b[?25hCollecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers==2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNLCw68nFu8W"
   },
   "source": [
    "## Training on twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3YwUM7V6OewJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrG4iXRJrAvE"
   },
   "source": [
    "#### Initialize bert classification model for 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330,
     "referenced_widgets": [
      "77a302bb0fee4bb9859beb40c300461f",
      "60297a4208244c259c0f0cd5cec98615",
      "d15b508d38044798b7b784cc94d3c2f4",
      "a9655fe3fdfe4957a232a44f5a61eef2",
      "a739eb5e6336400099d70d76cb71f8e5",
      "cdd86754bfb44389bd0a1084763c6ff6",
      "e4e0d3a879a74514af83e2adf49dd017",
      "39d6b10d834b425087187b29cce8db7f",
      "bc1aa5a19a7541db817fab9d42904cb1",
      "185bbf083b944a58ad2e016bcf693f41",
      "b4699b7a63404aa3acc77f8b88a3a0ef",
      "9f3673f0fa7f4cf48c976dee14582c2c",
      "9be1b3874c794c5dbacd5767785cade0",
      "57ae6d880e6a4632ad649b1c5e35ac6f",
      "bb6f3ebe241142beab7db8d8c554f021",
      "c327daef5bf349329eba9145a0cc196a",
      "34b8f35f8cc84a9687b7e144f78a7bc5",
      "b8fc393bd97144a1b31b6d56f657579a",
      "c2b857d759184ff5b407408e13b8c1f3",
      "2b8283368e634eaeab5380ec35f263c2",
      "471db887c8384b12a95ff74abb8039e3",
      "c53566cfa56c43eabd05f018e78dde61",
      "44aadc2560be495b8e9220e82293904a",
      "2df07e19db5e4a62bb4cd941c42d2b6e",
      "a3205bc24098437d925b399fa2f14eb4",
      "9788521fd35e4fca8e6bcfdf86be843f",
      "db485f17ba8a4ccc8e86c01d8c060166",
      "c33e8985a00e4c40974710b378abe633",
      "8ec03ebc88e149ba816b6a97e61dd40a",
      "5ea8008041824134ae0ce89822bb444f",
      "5c0c35abb15d4b43b7492d400a8ab182",
      "2664a59f18bb460cbbb4b07a42489d8b",
      "37f94a91b3ed4e74bbe87c05a2a043a7",
      "e8934b56fb1d426286800c3650d1b360",
      "94f802ef369f4492a4ef2fdb5f37b94a",
      "70ff435f15ea4d6d88ffa424925dfa8e",
      "90c7ba7a69324618a39353cf629b2528",
      "ec832b6bbeb14e669d373e8bfd506e88",
      "aad70965e8df469f99e5eee178ba65e6",
      "7104b66b3b074355bd325ce1d4d99fab"
     ]
    },
    "id": "SI4UAcYcOpxc",
    "outputId": "9c2fdbf8-b06f-4c5f-8431-f68c91c58dcc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a302bb0fee4bb9859beb40c300461f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1aa5a19a7541db817fab9d42904cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=536063208.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b8f35f8cc84a9687b7e144f78a7bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3205bc24098437d925b399fa2f14eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f94a91b3ed4e74bbe87c05a2a043a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", \n",
    "                                                        trainable=True, \n",
    "                                                        num_labels=3)\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97-sBX4P0Quk"
   },
   "source": [
    "Initialize checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tXpzylZOGzpT"
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_checkpoints/in_domain/twitter/cp_twitter.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaTErsaJst7w"
   },
   "source": [
    "Read hate dataset and convert it into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kd0PtS8gQqaq",
    "outputId": "3825cc11-bd3b-4073-b01d-727143a5a61c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet    24472\n",
       "label    24472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/twitter.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df['tweet'] = df['tweet'].str.strip()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6p4uB34gSwbI",
    "outputId": "09cb9ff0-4055-46e5-aaef-b1dfa93fb9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24472 entries, 0 to 24471\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   24472 non-null  object\n",
      " 1   label   24472 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 382.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0zjTXZXeHWg0"
   },
   "outputs": [],
   "source": [
    "def get_dataset(df, seed, test_size):\n",
    "    return train_test_split(df, test_size=test_size, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CgefoUK4RODW"
   },
   "outputs": [],
   "source": [
    "train, test = get_dataset(df, 11, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "bbG3RppguKks",
    "outputId": "80e9cb4f-9aa8-4745-c7b7-fe142f047012"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11983</th>\n",
       "      <td>K.Michelle talking bout can't raise no man wel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11244</th>\n",
       "      <td>I've got saltine crackers and red wine here. I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14490</th>\n",
       "      <td>: Udonis talking some big trash to Lance. LeBr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17351</th>\n",
       "      <td>: Your opinion is irrelevant because you are a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16205</th>\n",
       "      <td>: Scott Walker investigate. Christie's Bridgeg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  label\n",
       "11983  K.Michelle talking bout can't raise no man wel...      1\n",
       "11244  I've got saltine crackers and red wine here. I...      0\n",
       "14490  : Udonis talking some big trash to Lance. LeBr...      0\n",
       "17351  : Your opinion is irrelevant because you are a...      1\n",
       "16205  : Scott Walker investigate. Christie's Bridgeg...      0"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fKcwAZ0SIAmS",
    "outputId": "413366e4-b4fa-473d-b975-360a6d180362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19577 entries, 11983 to 10137\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   19577 non-null  object\n",
      " 1   label   19577 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 458.8+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fjBp7e80WqCQ"
   },
   "outputs": [],
   "source": [
    "train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_cdRKItSW0Cz"
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN): \n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "  \n",
    "  return train_InputExamples, validation_InputExamples\n",
    "\n",
    "  train_InputExamples, validation_InputExamples = convert_data_to_examples(train, \n",
    "                                                                           test, \n",
    "                                                                           'DATA_COLUMN', \n",
    "                                                                           'LABEL_COLUMN')\n",
    "  \n",
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOm1oM-HXaby",
    "outputId": "ae56d840-787a-4402-a7e9-05781d50525f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.batch(32)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ujXS3VX8XjpE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-6, epsilon=1e-08, clipnorm=1.0), \n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hhGM8DV9VEsc",
    "outputId": "b5f1c8d8-3447-4d86-f39f-92acb19e546f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc51eff3d70>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fc51eff3d70>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fc53a1a6170> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function wrap at 0x7fc53a1a6170> and will run it as-is.\n",
      "Cause: while/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "    612/Unknown - 524s 770ms/step - loss: 0.4495 - accuracy: 0.8453WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "612/612 [==============================] - 569s 843ms/step - loss: 0.4495 - accuracy: 0.8453 - val_loss: 0.2847 - val_accuracy: 0.9073\n",
      "\n",
      "Epoch 00001: saving model to training_checkpoints/in_domain/twitter/cp_twitter.ckpt\n",
      "Epoch 2/4\n",
      "612/612 [==============================] - 521s 851ms/step - loss: 0.2653 - accuracy: 0.9099 - val_loss: 0.2535 - val_accuracy: 0.9158\n",
      "\n",
      "Epoch 00002: saving model to training_checkpoints/in_domain/twitter/cp_twitter.ckpt\n",
      "Epoch 3/4\n",
      "612/612 [==============================] - 521s 851ms/step - loss: 0.2340 - accuracy: 0.9181 - val_loss: 0.2453 - val_accuracy: 0.9146\n",
      "\n",
      "Epoch 00003: saving model to training_checkpoints/in_domain/twitter/cp_twitter.ckpt\n",
      "Epoch 4/4\n",
      "612/612 [==============================] - 521s 851ms/step - loss: 0.2162 - accuracy: 0.9236 - val_loss: 0.2435 - val_accuracy: 0.9191\n",
      "\n",
      "Epoch 00004: saving model to training_checkpoints/in_domain/twitter/cp_twitter.ckpt\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_data, epochs=4, validation_data=validation_data, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWogEL_YnDJT",
    "outputId": "75e23845-9950-4c8a-a1d5-c36243408e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VZFSpUcQvNz2"
   },
   "outputs": [],
   "source": [
    "cr = classification_report(test['LABEL_COLUMN'],np.argmax(preds[0],axis=1),output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JJLTRyWYvT_N"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cr).transpose().to_csv('classification_reports/classification_bert_twitter_indomain.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJwpxJTO2Ldy"
   },
   "source": [
    "#### In-domain classification report for twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "LHZeKp0k7cqp",
    "outputId": "7b92b7f7-c053-404f-93ee-b56f4b2d4da8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.884754</td>\n",
       "      <td>0.905405</td>\n",
       "      <td>0.894961</td>\n",
       "      <td>814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.940467</td>\n",
       "      <td>0.965999</td>\n",
       "      <td>0.953062</td>\n",
       "      <td>3794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.587879</td>\n",
       "      <td>0.337979</td>\n",
       "      <td>0.429204</td>\n",
       "      <td>287.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.919101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.804367</td>\n",
       "      <td>0.736461</td>\n",
       "      <td>0.759075</td>\n",
       "      <td>4895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.910530</td>\n",
       "      <td>0.919101</td>\n",
       "      <td>0.912686</td>\n",
       "      <td>4895.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "0              0.884754  0.905405  0.894961   814.000000\n",
       "1              0.940467  0.965999  0.953062  3794.000000\n",
       "2              0.587879  0.337979  0.429204   287.000000\n",
       "accuracy       0.919101  0.919101  0.919101     0.919101\n",
       "macro avg      0.804367  0.736461  0.759075  4895.000000\n",
       "weighted avg   0.910530  0.919101  0.912686  4895.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cr).transpose() #  0: Normal speech, 1: Offensive speech, 2: Hate speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Of6cSDFrjTUq"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### Domain Adaptation, predicting on movies with the twitter trained model on 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "f-qYIKfU0Hbx"
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples_valid(data, DATA_COLUMN, LABEL_COLUMN): \n",
    "  train_InputExamples = data.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN], \n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  \n",
    "  return train_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "bWO0Gd0kJcjc"
   },
   "outputs": [],
   "source": [
    "df_movies = pd.read_csv('movies/all_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "qE7LKSArCTwl",
    "outputId": "149e4276-f958-4d99-dbe9-925118c7d61b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AmericanHistoryX(1998)_1</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>Derek.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AmericanHistoryX(1998)_2</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>1</td>\n",
       "      <td>What the fuck are you thinking?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  movie_id  ...  Unnamed: 6  Unnamed: 7\n",
       "0           0  AmericanHistoryX(1998)_1  ...         NaN         NaN\n",
       "1           1  AmericanHistoryX(1998)_2  ...         NaN         NaN\n",
       "\n",
       "[2 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "kPCquRoxzgbg",
    "outputId": "68e54500-be0e-423a-eec0-6eb7e9d6f491"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AmericanHistoryX(1998)_1</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>Derek.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AmericanHistoryX(1998)_2</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>1</td>\n",
       "      <td>What the fuck are you thinking?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AmericanHistoryX(1998)_3</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a black guy outside breaking into your...</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AmericanHistoryX(1998)_4</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>How long has he been there?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AmericanHistoryX(1998)_5</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  movie_id  ...  Unnamed: 6  Unnamed: 7\n",
       "0           0  AmericanHistoryX(1998)_1  ...         NaN         NaN\n",
       "1           1  AmericanHistoryX(1998)_2  ...         NaN         NaN\n",
       "2           2  AmericanHistoryX(1998)_3  ...         NaN         NaN\n",
       "3           3  AmericanHistoryX(1998)_4  ...         NaN         NaN\n",
       "4           4  AmericanHistoryX(1998)_5  ...         NaN         NaN\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies = df_movies.rename(columns={\"text\": \"DATA_COLUMN\", \"majority_answer\": \"LABEL_COLUMN\"})\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4crkpHOjzSU-"
   },
   "outputs": [],
   "source": [
    "movie_InputExamples = convert_data_to_examples_valid(df_movies, DATA_COLUMN, LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eye0NOKZ0X60",
    "outputId": "1072f16e-ef57-4cc7-8b1f-6550cb14b09c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "movie_data = convert_examples_to_tf_dataset(list(movie_InputExamples), tokenizer)\n",
    "movie_data = movie_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Y7Hj48JM0dQZ"
   },
   "outputs": [],
   "source": [
    "preds_movie = model.predict(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "LfGZDwCu1U4z"
   },
   "outputs": [],
   "source": [
    "cr_movies = classification_report(df_movies['LABEL_COLUMN'], np.argmax(preds_movie[0], axis=1), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "cyZGGzhH4hbU"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(cr_movies).transpose().to_csv('classification_reports/bert_twitter_domain_adap_movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRPGsVc42e18"
   },
   "source": [
    "#### Domain adaptation classification report from twitter on the movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "JxlniuH5jv88",
    "outputId": "5ccb283f-7f7e-4df1-c39c-310503990034"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.982884</td>\n",
       "      <td>0.917351</td>\n",
       "      <td>0.948987</td>\n",
       "      <td>9014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.628024</td>\n",
       "      <td>0.902899</td>\n",
       "      <td>0.740785</td>\n",
       "      <td>1380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.632302</td>\n",
       "      <td>0.625850</td>\n",
       "      <td>0.629060</td>\n",
       "      <td>294.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.907466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.747737</td>\n",
       "      <td>0.815367</td>\n",
       "      <td>0.772944</td>\n",
       "      <td>10688.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.927422</td>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.913304</td>\n",
       "      <td>10688.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score       support\n",
       "0              0.982884  0.917351  0.948987   9014.000000\n",
       "1              0.628024  0.902899  0.740785   1380.000000\n",
       "2              0.632302  0.625850  0.629060    294.000000\n",
       "accuracy       0.907466  0.907466  0.907466      0.907466\n",
       "macro avg      0.747737  0.815367  0.772944  10688.000000\n",
       "weighted avg   0.927422  0.907466  0.913304  10688.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cr_movies).transpose() # 0: None, 1: offensive, 2:hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J1kcn3M5nEi"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccJl8pYO5yI-"
   },
   "source": [
    "#### 6-fold cross validation on movies by fine tuning on above twitter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "6K6Nab3AAMPg"
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples_cv(train, DATA_COLUMN, LABEL_COLUMN):\n",
    "    train_InputExamples = train.apply(\n",
    "        lambda x: InputExample(guid=None,  # Globally unique ID for bookkeeping, unused in this case\n",
    "                               text_a=x[DATA_COLUMN],\n",
    "                               text_b=None,\n",
    "                               label=x[LABEL_COLUMN]), axis=1)\n",
    "\n",
    "    return train_InputExamples\n",
    "\n",
    "\n",
    "def convert_examples_to_tf_dataset_cv(examples, tokenizer, max_length=128):\n",
    "    features = []  # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,  # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True,  # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "                                                     input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_bert(df_train, df_test, load_training = False):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                        trainable=True,\n",
    "                                                        num_labels=3)\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    if load_training:\n",
    "        model.load_weights('training_checkpoints/in_domain/twitter/cp_twitter.ckpt')\n",
    "    train = df_train[['text', 'majority_answer']]\n",
    "    train.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "\n",
    "    test = df_test[['text', 'majority_answer']]\n",
    "    test.columns = ['DATA_COLUMN', 'LABEL_COLUMN']\n",
    "\n",
    "    DATA_COLUMN = 'DATA_COLUMN'\n",
    "    LABEL_COLUMN = 'LABEL_COLUMN'\n",
    "\n",
    "    train_InputExamples = convert_data_to_examples_cv(train, DATA_COLUMN, LABEL_COLUMN)\n",
    "    test_InputExamples = convert_data_to_examples_cv(test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "    train_data = convert_examples_to_tf_dataset_cv(list(train_InputExamples), tokenizer)\n",
    "    train_data = train_data.batch(32)\n",
    "\n",
    "    test_data = convert_examples_to_tf_dataset_cv(list(test_InputExamples), tokenizer)\n",
    "    test_data = test_data.batch(32)\n",
    "\n",
    "    # compile and fit\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-6, epsilon=1e-08, clipnorm=1.0),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "    model.fit(train_data, epochs=6)\n",
    "\n",
    "    print('predicting')\n",
    "    preds = model.predict(test_data)\n",
    "\n",
    "    # classification\n",
    "    return classification_report(test['LABEL_COLUMN'], np.argmax(preds[0], axis=1), output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "3-8P6vh8Np7i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "DWsFTqlHlgv3"
   },
   "outputs": [],
   "source": [
    "def load_movies_to_df(path):\n",
    "    df_movies = []\n",
    "\n",
    "    for filename in glob.glob(path + '*.csv'):\n",
    "        df_movies.append(pd.read_csv(filename))\n",
    "\n",
    "    return df_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Xz1rCrpvB2RA"
   },
   "outputs": [],
   "source": [
    "df_movies = load_movies_to_df('movies/for_training/')\n",
    "classification_reports = []\n",
    "df_main = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpchIXr0lciQ",
    "outputId": "1cfdd5ef-5860-4738-d4a8-0782492b2cf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "BlacKkKlansman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2190: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "283/283 [==============================] - 238s 774ms/step - loss: 0.1591 - accuracy: 0.9533\n",
      "Epoch 2/6\n",
      "283/283 [==============================] - 221s 780ms/step - loss: 0.1201 - accuracy: 0.9621\n",
      "Epoch 3/6\n",
      "283/283 [==============================] - 221s 780ms/step - loss: 0.1035 - accuracy: 0.9674\n",
      "Epoch 4/6\n",
      "283/283 [==============================] - 221s 780ms/step - loss: 0.0936 - accuracy: 0.9704\n",
      "Epoch 5/6\n",
      "283/283 [==============================] - 221s 780ms/step - loss: 0.0796 - accuracy: 0.9749\n",
      "Epoch 6/6\n",
      "283/283 [==============================] - 221s 780ms/step - loss: 0.0682 - accuracy: 0.9789\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Test movie:  BlacKkKlansman\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9695035460992908, 'recall': 0.9350205198358413, 'f1-score': 0.9519498607242339, 'support': 1462}, '1': {'precision': 0.5042735042735043, 'recall': 0.6082474226804123, 'f1-score': 0.5514018691588785, 'support': 97}, '2': {'precision': 0.5084745762711864, 'recall': 0.6976744186046512, 'f1-score': 0.5882352941176471, 'support': 86}, 'accuracy': 0.9033434650455927, 'macro avg': {'precision': 0.6607505422146605, 'recall': 0.7469807870403016, 'f1-score': 0.6971956746669199, 'support': 1645}, 'weighted avg': {'precision': 0.9179681020492494, 'recall': 0.9033434650455927, 'f1-score': 0.9093160565236225, 'support': 1645}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Pulp_Fiction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "284/284 [==============================] - 239s 770ms/step - loss: 0.1626 - accuracy: 0.9520\n",
      "Epoch 2/6\n",
      "284/284 [==============================] - 221s 780ms/step - loss: 0.1236 - accuracy: 0.9615\n",
      "Epoch 3/6\n",
      "284/284 [==============================] - 221s 780ms/step - loss: 0.1062 - accuracy: 0.9670\n",
      "Epoch 4/6\n",
      "284/284 [==============================] - 221s 780ms/step - loss: 0.0922 - accuracy: 0.9704\n",
      "Epoch 5/6\n",
      "284/284 [==============================] - 221s 780ms/step - loss: 0.0779 - accuracy: 0.9745\n",
      "Epoch 6/6\n",
      "284/284 [==============================] - 222s 780ms/step - loss: 0.0666 - accuracy: 0.9788\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Test movie:  Pulp_Fiction\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9676691729323308, 'recall': 0.9654913728432108, 'f1-score': 0.9665790461885092, 'support': 1333}, '1': {'precision': 0.8270676691729323, 'recall': 0.8301886792452831, 'f1-score': 0.8286252354048963, 'support': 265}, '2': {'precision': 0.7692307692307693, 'recall': 0.8333333333333334, 'f1-score': 0.8, 'support': 24}, 'accuracy': 0.9414303329223181, 'macro avg': {'precision': 0.8546558704453441, 'recall': 0.8763377951406092, 'f1-score': 0.8650680938644685, 'support': 1622}, 'weighted avg': {'precision': 0.9417617005617526, 'recall': 0.9414303329223181, 'f1-score': 0.9415755585398151, 'support': 1622}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "AmerricanHistoryX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "286/286 [==============================] - 242s 775ms/step - loss: 0.1610 - accuracy: 0.9511\n",
      "Epoch 2/6\n",
      "286/286 [==============================] - 223s 779ms/step - loss: 0.1236 - accuracy: 0.9614\n",
      "Epoch 3/6\n",
      "286/286 [==============================] - 223s 779ms/step - loss: 0.1066 - accuracy: 0.9654\n",
      "Epoch 4/6\n",
      "286/286 [==============================] - 223s 779ms/step - loss: 0.0947 - accuracy: 0.9693\n",
      "Epoch 5/6\n",
      "286/286 [==============================] - 223s 779ms/step - loss: 0.0816 - accuracy: 0.9751\n",
      "Epoch 6/6\n",
      "286/286 [==============================] - 223s 779ms/step - loss: 0.0720 - accuracy: 0.9786\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,TheWolfofWallStreet,Django_Unchained,South_Park\n",
      "Test movie:  AmerricanHistoryX\n",
      "Classification report: \n",
      " {'0': {'precision': 0.969488939740656, 'recall': 0.9746932515337423, 'f1-score': 0.9720841300191205, 'support': 1304}, '1': {'precision': 0.7867298578199052, 'recall': 0.8019323671497585, 'f1-score': 0.7942583732057417, 'support': 207}, '2': {'precision': 0.7674418604651163, 'recall': 0.6111111111111112, 'f1-score': 0.6804123711340206, 'support': 54}, 'accuracy': 0.939297124600639, 'macro avg': {'precision': 0.8412202193418925, 'recall': 0.7959122432648705, 'f1-score': 0.8155849581196275, 'support': 1565}, 'weighted avg': {'precision': 0.9383441012496179, 'recall': 0.939297124600639, 'f1-score': 0.9384993334439354, 'support': 1565}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,Django_Unchained,South_Park\n",
      "TheWolfofWallStreet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "239/239 [==============================] - 203s 768ms/step - loss: 0.1945 - accuracy: 0.9401\n",
      "Epoch 2/6\n",
      "239/239 [==============================] - 186s 779ms/step - loss: 0.1507 - accuracy: 0.9530\n",
      "Epoch 3/6\n",
      "239/239 [==============================] - 186s 778ms/step - loss: 0.1324 - accuracy: 0.9583\n",
      "Epoch 4/6\n",
      "239/239 [==============================] - 186s 779ms/step - loss: 0.1170 - accuracy: 0.9620\n",
      "Epoch 5/6\n",
      "239/239 [==============================] - 186s 780ms/step - loss: 0.1045 - accuracy: 0.9668\n",
      "Epoch 6/6\n",
      "239/239 [==============================] - 186s 779ms/step - loss: 0.0902 - accuracy: 0.9723\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,Django_Unchained,South_Park\n",
      "Test movie:  TheWolfofWallStreet\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9834142394822006, 'recall': 0.9826192400970089, 'f1-score': 0.9830165790537807, 'support': 2474}, '1': {'precision': 0.9304347826086956, 'recall': 0.9114139693356048, 'f1-score': 0.9208261617900172, 'support': 587}, '2': {'precision': 0.125, 'recall': 1.0, 'f1-score': 0.2222222222222222, 'support': 2}, 'accuracy': 0.9689846555664381, 'macro avg': {'precision': 0.6796163406969654, 'recall': 0.964677736477538, 'f1-score': 0.7086883210220067, 'support': 3063}, 'weighted avg': {'precision': 0.9727006352824906, 'recall': 0.9689846555664381, 'f1-score': 0.9706015076703357, 'support': 3063}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,South_Park\n",
      "Django_Unchained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "280/280 [==============================] - 238s 777ms/step - loss: 0.1729 - accuracy: 0.9469\n",
      "Epoch 2/6\n",
      "280/280 [==============================] - 218s 780ms/step - loss: 0.1340 - accuracy: 0.9579\n",
      "Epoch 3/6\n",
      "280/280 [==============================] - 219s 780ms/step - loss: 0.1167 - accuracy: 0.9632\n",
      "Epoch 4/6\n",
      "280/280 [==============================] - 218s 780ms/step - loss: 0.1085 - accuracy: 0.9664\n",
      "Epoch 5/6\n",
      "280/280 [==============================] - 218s 780ms/step - loss: 0.0923 - accuracy: 0.9706\n",
      "Epoch 6/6\n",
      "280/280 [==============================] - 218s 780ms/step - loss: 0.0804 - accuracy: 0.9747\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,South_Park\n",
      "Test movie:  Django_Unchained\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9838082901554405, 'recall': 0.9793681495809156, 'f1-score': 0.981583198707593, 'support': 1551}, '1': {'precision': 0.632183908045977, 'recall': 0.6962025316455697, 'f1-score': 0.6626506024096386, 'support': 79}, '2': {'precision': 0.9568965517241379, 'recall': 0.9487179487179487, 'f1-score': 0.9527896995708154, 'support': 117}, 'accuracy': 0.9645105895821409, 'macro avg': {'precision': 0.8576295833085185, 'recall': 0.8747628766481447, 'f1-score': 0.8656745002293489, 'support': 1747}, 'weighted avg': {'precision': 0.9661053711038606, 'recall': 0.9645105895821409, 'f1-score': 0.9652325893735683, 'support': 1747}}\n",
      "------------------------------------------------\n",
      "BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained\n",
      "South_Park\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "302/302 [==============================] - 253s 776ms/step - loss: 0.1595 - accuracy: 0.9516\n",
      "Epoch 2/6\n",
      "302/302 [==============================] - 235s 780ms/step - loss: 0.1223 - accuracy: 0.9617\n",
      "Epoch 3/6\n",
      "302/302 [==============================] - 235s 779ms/step - loss: 0.1076 - accuracy: 0.9657\n",
      "Epoch 4/6\n",
      "302/302 [==============================] - 235s 779ms/step - loss: 0.0942 - accuracy: 0.9702\n",
      "Epoch 5/6\n",
      "302/302 [==============================] - 235s 779ms/step - loss: 0.0842 - accuracy: 0.9730\n",
      "Epoch 6/6\n",
      "302/302 [==============================] - 235s 779ms/step - loss: 0.0713 - accuracy: 0.9783\n",
      "predicting\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "Train movies:  BlacKkKlansman,Pulp_Fiction,AmerricanHistoryX,TheWolfofWallStreet,Django_Unchained\n",
      "Test movie:  South_Park\n",
      "Classification report: \n",
      " {'0': {'precision': 0.9488574537540805, 'recall': 0.9797752808988764, 'f1-score': 0.9640685461580983, 'support': 890}, '1': {'precision': 0.8547008547008547, 'recall': 0.6896551724137931, 'f1-score': 0.7633587786259542, 'support': 145}, '2': {'precision': 0.3, 'recall': 0.2727272727272727, 'f1-score': 0.28571428571428564, 'support': 11}, 'accuracy': 0.9321223709369025, 'macro avg': {'precision': 0.7011861028183116, 'recall': 0.6473859086799808, 'f1-score': 0.671047203499446, 'support': 1046}, 'weighted avg': {'precision': 0.9289816039892499, 'recall': 0.9321223709369025, 'f1-score': 0.9291117458167572, 'support': 1046}}\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# perform cross folding\n",
    "for i in range(len(df_movies)):\n",
    "    df_train = pd.concat(df_movies[0:i] + df_movies[i + 1:])\n",
    "    df_test = df_movies[i]\n",
    "\n",
    "    train_movies = df_train['movie_name'].unique()\n",
    "    test_movie = df_test['movie_name'].unique()\n",
    "    print(','.join(train_movies))\n",
    "    print(test_movie[0])\n",
    "    classification_reports.append(train_bert(df_train, df_test, True))\n",
    "    \n",
    "    print('Train movies: ', str(','.join(train_movies)))\n",
    "    print('Test movie: ', str(test_movie[0]))\n",
    "    print('Classification report: \\n', classification_reports[i])\n",
    "    print('------------------------------------------------')\n",
    "\n",
    "    df_cr = pd.DataFrame(classification_reports[i]).transpose()\n",
    "    df_cr['movie_train'] =  str(','.join(train_movies))\n",
    "    df_cr['movie_test'] = str(test_movie[0])\n",
    "    df_cr.to_csv('classification_reports/'+'bert_twitter_cv_finetune_testmovie_'+str(test_movie[0])+'.csv')\n",
    "    df_main = df_main.append(df_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LyfPoHfVB63k"
   },
   "outputs": [],
   "source": [
    "df_main.to_csv('classification_reports/bert_crossvalid_finetune_twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9c-yeiBHfGG",
    "outputId": "e5071a61-8489-4ad3-dfb0-c9e475004788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision  ...           movie_test\n",
      "0              0.969504  ...       BlacKkKlansman\n",
      "1              0.504274  ...       BlacKkKlansman\n",
      "2              0.508475  ...       BlacKkKlansman\n",
      "accuracy       0.903343  ...       BlacKkKlansman\n",
      "macro avg      0.660751  ...       BlacKkKlansman\n",
      "weighted avg   0.917968  ...       BlacKkKlansman\n",
      "0              0.967669  ...         Pulp_Fiction\n",
      "1              0.827068  ...         Pulp_Fiction\n",
      "2              0.769231  ...         Pulp_Fiction\n",
      "accuracy       0.941430  ...         Pulp_Fiction\n",
      "macro avg      0.854656  ...         Pulp_Fiction\n",
      "weighted avg   0.941762  ...         Pulp_Fiction\n",
      "0              0.969489  ...    AmerricanHistoryX\n",
      "1              0.786730  ...    AmerricanHistoryX\n",
      "2              0.767442  ...    AmerricanHistoryX\n",
      "accuracy       0.939297  ...    AmerricanHistoryX\n",
      "macro avg      0.841220  ...    AmerricanHistoryX\n",
      "weighted avg   0.938344  ...    AmerricanHistoryX\n",
      "0              0.983414  ...  TheWolfofWallStreet\n",
      "1              0.930435  ...  TheWolfofWallStreet\n",
      "2              0.125000  ...  TheWolfofWallStreet\n",
      "accuracy       0.968985  ...  TheWolfofWallStreet\n",
      "macro avg      0.679616  ...  TheWolfofWallStreet\n",
      "weighted avg   0.972701  ...  TheWolfofWallStreet\n",
      "0              0.983808  ...     Django_Unchained\n",
      "1              0.632184  ...     Django_Unchained\n",
      "2              0.956897  ...     Django_Unchained\n",
      "accuracy       0.964511  ...     Django_Unchained\n",
      "macro avg      0.857630  ...     Django_Unchained\n",
      "weighted avg   0.966105  ...     Django_Unchained\n",
      "0              0.948857  ...           South_Park\n",
      "1              0.854701  ...           South_Park\n",
      "2              0.300000  ...           South_Park\n",
      "accuracy       0.932122  ...           South_Park\n",
      "macro avg      0.701186  ...           South_Park\n",
      "weighted avg   0.928982  ...           South_Park\n",
      "\n",
      "[36 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iD3D9odZB7de",
    "outputId": "8f0d8e1f-14cb-492d-a3c6-4c4be80f68e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classification_reports[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "68L-CNl6GGg8",
    "outputId": "56633258-ebc6-4225-9630-4a1cabec8ba3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>movie_train</th>\n",
       "      <th>movie_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.969504</td>\n",
       "      <td>0.935021</td>\n",
       "      <td>0.951950</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.903343</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.660751</td>\n",
       "      <td>0.746981</td>\n",
       "      <td>0.697196</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision  ...      movie_test\n",
       "0           0.969504  ...  BlacKkKlansman\n",
       "1           0.504274  ...  BlacKkKlansman\n",
       "2           0.508475  ...  BlacKkKlansman\n",
       "accuracy    0.903343  ...  BlacKkKlansman\n",
       "macro avg   0.660751  ...  BlacKkKlansman\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "NRGObHolGHHF"
   },
   "outputs": [],
   "source": [
    "def get_precision_recall_f1(category, result_df):\n",
    "    precision = result_df[result_df.label==category].precision.mean()\n",
    "    recall = result_df[result_df.label==category].recall.mean()\n",
    "    f1 = result_df[result_df.label==category]['f1-score'].mean()\n",
    "    \n",
    "    return {'label': category, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "PVRT0b1thTtB"
   },
   "outputs": [],
   "source": [
    "df_cv= pd.read_csv('classification_reports/bert_crossvalid_finetune_twitter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "SnXkEFJlmfSU",
    "outputId": "d7f90212-fe72-456a-e4bc-a2cc14d33e72"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>movie_train</th>\n",
       "      <th>movie_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.969504</td>\n",
       "      <td>0.935021</td>\n",
       "      <td>0.951950</td>\n",
       "      <td>1462.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.608247</td>\n",
       "      <td>0.551402</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>0.903343</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.660751</td>\n",
       "      <td>0.746981</td>\n",
       "      <td>0.697196</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>Pulp_Fiction,AmerricanHistoryX,TheWolfofWallSt...</td>\n",
       "      <td>BlacKkKlansman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  ...      movie_test\n",
       "0          0  ...  BlacKkKlansman\n",
       "1          1  ...  BlacKkKlansman\n",
       "2          2  ...  BlacKkKlansman\n",
       "3   accuracy  ...  BlacKkKlansman\n",
       "4  macro avg  ...  BlacKkKlansman\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv = df_cv.rename(columns={'Unnamed: 0': 'label', 'b': 'Y'})\n",
    "df_cv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "V81usTykmsnl"
   },
   "outputs": [],
   "source": [
    "normal_dict = get_precision_recall_f1('0', df_cv)\n",
    "offensive_dict = get_precision_recall_f1('1',df_cv)\n",
    "hate_dict = get_precision_recall_f1('2',df_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregated results of all 6 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "9xnoFFrOmgu1",
    "outputId": "791e4815-ea99-4f08-b497-fd2b6a046fe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.970457</td>\n",
       "      <td>0.969495</td>\n",
       "      <td>0.969880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.755898</td>\n",
       "      <td>0.756273</td>\n",
       "      <td>0.753520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.571174</td>\n",
       "      <td>0.727261</td>\n",
       "      <td>0.588229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  precision    recall        f1\n",
       "0     0   0.970457  0.969495  0.969880\n",
       "1     1   0.755898  0.756273  0.753520\n",
       "2     2   0.571174  0.727261  0.588229"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.DataFrame([normal_dict, offensive_dict, hate_dict])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLHfd4BFnloL",
    "outputId": "bc8f2090-258f-46b6-a8cf-2145b770750f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.9695035460992908, 'recall': 0.9350205198358413, 'f1-score': 0.9519498607242339, 'support': 1462}, '1': {'precision': 0.5042735042735043, 'recall': 0.6082474226804123, 'f1-score': 0.5514018691588785, 'support': 97}, '2': {'precision': 0.5084745762711864, 'recall': 0.6976744186046512, 'f1-score': 0.5882352941176471, 'support': 86}, 'accuracy': 0.9033434650455927, 'macro avg': {'precision': 0.6607505422146605, 'recall': 0.7469807870403016, 'f1-score': 0.6971956746669199, 'support': 1645}, 'weighted avg': {'precision': 0.9179681020492494, 'recall': 0.9033434650455927, 'f1-score': 0.9093160565236225, 'support': 1645}}\n",
      "{'0': {'precision': 0.9676691729323308, 'recall': 0.9654913728432108, 'f1-score': 0.9665790461885092, 'support': 1333}, '1': {'precision': 0.8270676691729323, 'recall': 0.8301886792452831, 'f1-score': 0.8286252354048963, 'support': 265}, '2': {'precision': 0.7692307692307693, 'recall': 0.8333333333333334, 'f1-score': 0.8, 'support': 24}, 'accuracy': 0.9414303329223181, 'macro avg': {'precision': 0.8546558704453441, 'recall': 0.8763377951406092, 'f1-score': 0.8650680938644685, 'support': 1622}, 'weighted avg': {'precision': 0.9417617005617526, 'recall': 0.9414303329223181, 'f1-score': 0.9415755585398151, 'support': 1622}}\n",
      "{'0': {'precision': 0.969488939740656, 'recall': 0.9746932515337423, 'f1-score': 0.9720841300191205, 'support': 1304}, '1': {'precision': 0.7867298578199052, 'recall': 0.8019323671497585, 'f1-score': 0.7942583732057417, 'support': 207}, '2': {'precision': 0.7674418604651163, 'recall': 0.6111111111111112, 'f1-score': 0.6804123711340206, 'support': 54}, 'accuracy': 0.939297124600639, 'macro avg': {'precision': 0.8412202193418925, 'recall': 0.7959122432648705, 'f1-score': 0.8155849581196275, 'support': 1565}, 'weighted avg': {'precision': 0.9383441012496179, 'recall': 0.939297124600639, 'f1-score': 0.9384993334439354, 'support': 1565}}\n",
      "{'0': {'precision': 0.9834142394822006, 'recall': 0.9826192400970089, 'f1-score': 0.9830165790537807, 'support': 2474}, '1': {'precision': 0.9304347826086956, 'recall': 0.9114139693356048, 'f1-score': 0.9208261617900172, 'support': 587}, '2': {'precision': 0.125, 'recall': 1.0, 'f1-score': 0.2222222222222222, 'support': 2}, 'accuracy': 0.9689846555664381, 'macro avg': {'precision': 0.6796163406969654, 'recall': 0.964677736477538, 'f1-score': 0.7086883210220067, 'support': 3063}, 'weighted avg': {'precision': 0.9727006352824906, 'recall': 0.9689846555664381, 'f1-score': 0.9706015076703357, 'support': 3063}}\n",
      "{'0': {'precision': 0.9838082901554405, 'recall': 0.9793681495809156, 'f1-score': 0.981583198707593, 'support': 1551}, '1': {'precision': 0.632183908045977, 'recall': 0.6962025316455697, 'f1-score': 0.6626506024096386, 'support': 79}, '2': {'precision': 0.9568965517241379, 'recall': 0.9487179487179487, 'f1-score': 0.9527896995708154, 'support': 117}, 'accuracy': 0.9645105895821409, 'macro avg': {'precision': 0.8576295833085185, 'recall': 0.8747628766481447, 'f1-score': 0.8656745002293489, 'support': 1747}, 'weighted avg': {'precision': 0.9661053711038606, 'recall': 0.9645105895821409, 'f1-score': 0.9652325893735683, 'support': 1747}}\n",
      "{'0': {'precision': 0.9488574537540805, 'recall': 0.9797752808988764, 'f1-score': 0.9640685461580983, 'support': 890}, '1': {'precision': 0.8547008547008547, 'recall': 0.6896551724137931, 'f1-score': 0.7633587786259542, 'support': 145}, '2': {'precision': 0.3, 'recall': 0.2727272727272727, 'f1-score': 0.28571428571428564, 'support': 11}, 'accuracy': 0.9321223709369025, 'macro avg': {'precision': 0.7011861028183116, 'recall': 0.6473859086799808, 'f1-score': 0.671047203499446, 'support': 1046}, 'weighted avg': {'precision': 0.9289816039892499, 'recall': 0.9321223709369025, 'f1-score': 0.9291117458167572, 'support': 1046}}\n"
     ]
    }
   ],
   "source": [
    "for cr in classification_reports:\n",
    "  print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "rPVfWb2BDZ3z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_twitter_domain_adap_cv.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "185bbf083b944a58ad2e016bcf693f41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2664a59f18bb460cbbb4b07a42489d8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b8283368e634eaeab5380ec35f263c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2df07e19db5e4a62bb4cd941c42d2b6e",
      "placeholder": "​",
      "style": "IPY_MODEL_44aadc2560be495b8e9220e82293904a",
      "value": " 232k/232k [00:01&lt;00:00, 174kB/s]"
     }
    },
    "2df07e19db5e4a62bb4cd941c42d2b6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34b8f35f8cc84a9687b7e144f78a7bc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c2b857d759184ff5b407408e13b8c1f3",
       "IPY_MODEL_2b8283368e634eaeab5380ec35f263c2"
      ],
      "layout": "IPY_MODEL_b8fc393bd97144a1b31b6d56f657579a"
     }
    },
    "37f94a91b3ed4e74bbe87c05a2a043a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94f802ef369f4492a4ef2fdb5f37b94a",
       "IPY_MODEL_70ff435f15ea4d6d88ffa424925dfa8e"
      ],
      "layout": "IPY_MODEL_e8934b56fb1d426286800c3650d1b360"
     }
    },
    "39d6b10d834b425087187b29cce8db7f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44aadc2560be495b8e9220e82293904a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "471db887c8384b12a95ff74abb8039e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "57ae6d880e6a4632ad649b1c5e35ac6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c0c35abb15d4b43b7492d400a8ab182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ea8008041824134ae0ce89822bb444f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60297a4208244c259c0f0cd5cec98615": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70ff435f15ea4d6d88ffa424925dfa8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7104b66b3b074355bd325ce1d4d99fab",
      "placeholder": "​",
      "style": "IPY_MODEL_aad70965e8df469f99e5eee178ba65e6",
      "value": " 466k/466k [00:00&lt;00:00, 2.14MB/s]"
     }
    },
    "7104b66b3b074355bd325ce1d4d99fab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77a302bb0fee4bb9859beb40c300461f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d15b508d38044798b7b784cc94d3c2f4",
       "IPY_MODEL_a9655fe3fdfe4957a232a44f5a61eef2"
      ],
      "layout": "IPY_MODEL_60297a4208244c259c0f0cd5cec98615"
     }
    },
    "8ec03ebc88e149ba816b6a97e61dd40a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "90c7ba7a69324618a39353cf629b2528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "94f802ef369f4492a4ef2fdb5f37b94a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec832b6bbeb14e669d373e8bfd506e88",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_90c7ba7a69324618a39353cf629b2528",
      "value": 466062
     }
    },
    "9788521fd35e4fca8e6bcfdf86be843f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9be1b3874c794c5dbacd5767785cade0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9f3673f0fa7f4cf48c976dee14582c2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c327daef5bf349329eba9145a0cc196a",
      "placeholder": "​",
      "style": "IPY_MODEL_bb6f3ebe241142beab7db8d8c554f021",
      "value": " 536M/536M [00:33&lt;00:00, 16.2MB/s]"
     }
    },
    "a3205bc24098437d925b399fa2f14eb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db485f17ba8a4ccc8e86c01d8c060166",
       "IPY_MODEL_c33e8985a00e4c40974710b378abe633"
      ],
      "layout": "IPY_MODEL_9788521fd35e4fca8e6bcfdf86be843f"
     }
    },
    "a739eb5e6336400099d70d76cb71f8e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a9655fe3fdfe4957a232a44f5a61eef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39d6b10d834b425087187b29cce8db7f",
      "placeholder": "​",
      "style": "IPY_MODEL_e4e0d3a879a74514af83e2adf49dd017",
      "value": " 570/570 [00:00&lt;00:00, 11.7kB/s]"
     }
    },
    "aad70965e8df469f99e5eee178ba65e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4699b7a63404aa3acc77f8b88a3a0ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57ae6d880e6a4632ad649b1c5e35ac6f",
      "max": 536063208,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9be1b3874c794c5dbacd5767785cade0",
      "value": 536063208
     }
    },
    "b8fc393bd97144a1b31b6d56f657579a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb6f3ebe241142beab7db8d8c554f021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bc1aa5a19a7541db817fab9d42904cb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4699b7a63404aa3acc77f8b88a3a0ef",
       "IPY_MODEL_9f3673f0fa7f4cf48c976dee14582c2c"
      ],
      "layout": "IPY_MODEL_185bbf083b944a58ad2e016bcf693f41"
     }
    },
    "c2b857d759184ff5b407408e13b8c1f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c53566cfa56c43eabd05f018e78dde61",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_471db887c8384b12a95ff74abb8039e3",
      "value": 231508
     }
    },
    "c327daef5bf349329eba9145a0cc196a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c33e8985a00e4c40974710b378abe633": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2664a59f18bb460cbbb4b07a42489d8b",
      "placeholder": "​",
      "style": "IPY_MODEL_5c0c35abb15d4b43b7492d400a8ab182",
      "value": " 28.0/28.0 [00:00&lt;00:00, 31.6B/s]"
     }
    },
    "c53566cfa56c43eabd05f018e78dde61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdd86754bfb44389bd0a1084763c6ff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d15b508d38044798b7b784cc94d3c2f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdd86754bfb44389bd0a1084763c6ff6",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a739eb5e6336400099d70d76cb71f8e5",
      "value": 570
     }
    },
    "db485f17ba8a4ccc8e86c01d8c060166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5ea8008041824134ae0ce89822bb444f",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ec03ebc88e149ba816b6a97e61dd40a",
      "value": 28
     }
    },
    "e4e0d3a879a74514af83e2adf49dd017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e8934b56fb1d426286800c3650d1b360": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec832b6bbeb14e669d373e8bfd506e88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
