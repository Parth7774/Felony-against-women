{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmericanHistoryX(1998)_1</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>Derek.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmericanHistoryX(1998)_2</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>1</td>\n",
       "      <td>What the fuck are you thinking?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmericanHistoryX(1998)_3</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a black guy outside breaking into your...</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmericanHistoryX(1998)_4</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>How long has he been there?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmericanHistoryX(1998)_5</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_id    batch_id  label  \\\n",
       "0  AmericanHistoryX(1998)_1  1566624979      0   \n",
       "1  AmericanHistoryX(1998)_2  1566624979      1   \n",
       "2  AmericanHistoryX(1998)_3  1566624979      0   \n",
       "3  AmericanHistoryX(1998)_4  1566624979      0   \n",
       "4  AmericanHistoryX(1998)_5  1566624979      0   \n",
       "\n",
       "                                                text         movie_name  \n",
       "0                                             Derek.  AmerricanHistoryX  \n",
       "1                    What the fuck are you thinking?  AmerricanHistoryX  \n",
       "2  There's a black guy outside breaking into your...  AmerricanHistoryX  \n",
       "3                        How long has he been there?  AmerricanHistoryX  \n",
       "4                                      I don't know.  AmerricanHistoryX  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'E:\\github\\movie_hatespeech_detection\\data\\movies_for_training\\all_movies.csv'\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df = df.rename(columns={'majority_answer': 'label'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10688"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02750748502994012"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.label==2].shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9014\n",
      "1    1380\n",
      "2     294\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:ylabel='label'>], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.label.value_counts())\n",
    "df.label.value_counts().plot(kind='pie', subplots=True, autopct='%1.0f%%', title='Hate Speech Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names = df.movie_name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, test_movie, seed):\n",
    "    test = df[df.movie_name == test_movie]\n",
    "    train = df[df.movie_name != test_movie]\n",
    "    train = train.sample(frac=1, random_state=seed)\n",
    "    return train.text.values, train.label.values, test.text.values, test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0,1,2]\n",
    "seed = 11\n",
    "movie_index = 5\n",
    "test_movie = movie_names[movie_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets, test, test_targets = split_dataset(df, test_movie, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7625\n",
      "3063\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_class_distribution(targets, categories):\n",
    "    df = pd.DataFrame({'category':targets})\n",
    "    s = df.category.value_counts(normalize=True)\n",
    "    s = s.reindex(categories)\n",
    "    return [s.index[0], s[0]], [s.index[1], s[1]], [s.index[2], s[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0.8577049180327869], [1, 0.104], [2, 0.03829508196721312])\n",
      "([0, 0.8077048645119165], [1, 0.19164218086842966], [2, 0.000652954619653934])\n"
     ]
    }
   ],
   "source": [
    "train_class_distribution = calculate_dataset_class_distribution(train_targets, categories)\n",
    "test_class_distribution = calculate_dataset_class_distribution(test_targets, categories)\n",
    "print(train_class_distribution)\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Bunch(data=train, target=train_targets)\n",
    "test_ds = Bunch(data=test, target=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the vocabularies and indexing to a unique position\n",
    "vocab = Counter()\n",
    "#Indexing words from the training data\n",
    "for text in train_ds.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "#Indexing words from the training data\n",
    "for text in test_ds.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "        \n",
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "\n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12836\n",
      "3\n",
      "12836\n"
     ]
    }
   ],
   "source": [
    "print(len(word2index))\n",
    "print(word2index[\"the\"]) # Showing the index of 'the'\n",
    "print (total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "class News_20_Net(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(News_20_Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True).cuda()\n",
    "        self.relu = nn.ReLU().cuda()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True).cuda()\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True).cuda()\n",
    "    # accept input and return an output\n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(df,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    # Split into different batchs, get the next batch \n",
    "    texts = df.data[i*batch_size:i*batch_size+batch_size]\n",
    "    # get the targets \n",
    "    categories = df.target[i*batch_size:i*batch_size+batch_size]\n",
    "    #print(categories)\n",
    "    for text in texts:\n",
    "        # Dimension, 196609\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "        batches.append(layer)\n",
    "\n",
    "    # We have 5 categories\n",
    "    for category in categories:\n",
    "        #print(category)\n",
    "        index_y = -1\n",
    "        if category == 0:\n",
    "            index_y = 0\n",
    "        elif category == 1:\n",
    "            index_y = 1\n",
    "        elif category == 2:\n",
    "            index_y = 2\n",
    "        results.append(index_y)\n",
    "\n",
    "    # the training and the targets\n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 8\n",
    "batch_size = 32\n",
    "display_step = 10 # ADDED will multiplied by 10\n",
    "\n",
    "# Network Parameters\n",
    "hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "input_size = total_words # Words in vocab\n",
    "num_classes = len(categories)         # Categories: \"graphics\",\"space\",\"baseball\",\"guns\", \"christian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 1, 'Step': 100, 'Loss': 0.2353789508342743}\n",
      "{'Epoch': 1, 'Step': 200, 'Loss': 0.24079222977161407}\n",
      "{'Epoch': 2, 'Step': 100, 'Loss': 0.11936569213867188}\n",
      "{'Epoch': 2, 'Step': 200, 'Loss': 0.11606612801551819}\n",
      "{'Epoch': 3, 'Step': 100, 'Loss': 0.0728338211774826}\n",
      "{'Epoch': 3, 'Step': 200, 'Loss': 0.012335972860455513}\n",
      "{'Epoch': 4, 'Step': 100, 'Loss': 0.06808780133724213}\n",
      "{'Epoch': 4, 'Step': 200, 'Loss': 0.0015068287029862404}\n",
      "{'Epoch': 5, 'Step': 100, 'Loss': 0.081565722823143}\n",
      "{'Epoch': 5, 'Step': 200, 'Loss': 0.00020875992777291685}\n",
      "{'Epoch': 6, 'Step': 100, 'Loss': 0.10151759535074234}\n",
      "{'Epoch': 6, 'Step': 200, 'Loss': 8.279733447125182e-05}\n",
      "{'Epoch': 7, 'Step': 100, 'Loss': 0.09458906948566437}\n",
      "{'Epoch': 7, 'Step': 200, 'Loss': 3.831751746474765e-05}\n",
      "{'Epoch': 8, 'Step': 100, 'Loss': 0.09315795451402664}\n",
      "{'Epoch': 8, 'Step': 200, 'Loss': 2.2156653358251788e-05}\n"
     ]
    }
   ],
   "source": [
    "news_net = News_20_Net(input_size, hidden_size, num_classes)\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # This includes the Softmax loss function\n",
    "optimizer = torch.optim.Adam(news_net.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    # determine the number of min-batches based on the batch size and size of training data\n",
    "    total_batch = int(len(train_ds.data)/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_ds,i,batch_size)\n",
    "        \n",
    "        articles = torch.cuda.FloatTensor(batch_x, device='cuda')\n",
    "        labels = torch.cuda.LongTensor(batch_y, device='cuda')\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = news_net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % display_step == 0:\n",
    "            result = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f'%(epoch+1, num_epochs, i+1, len(train_ds.data)/batch_size, loss.data)\n",
    "            results.append({'Epoch': epoch+1, 'Step': i+1, 'Loss': loss.data.item()})\n",
    "            if (i+1) % (display_step*10) == 0:\n",
    "                print({'Epoch': epoch+1, 'Step': i+1, 'Loss': loss.data.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_test_data = len(test_ds.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterates = total_test_data/batch_size # ignore last (<batch_size) batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total = []\n",
    "all_correct = []\n",
    "labels_all = []\n",
    "predicted_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(iterates)):\n",
    "    batch_x_test,batch_y_test = get_batch(test_ds,i,batch_size)\n",
    "    articles = torch.FloatTensor(batch_x_test).to('cuda')\n",
    "    labels = torch.LongTensor(batch_y_test).to('cuda')\n",
    "    outputs = news_net(articles)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    labels_all.extend([x.item() for x in labels])\n",
    "    predicted_all.extend([x.item() for x in predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['normal', 'offensive', 'hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(labels_all, predicted_all, target_names=categories, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report.to_csv(movie_names[movie_index] + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['learning_rate'] = learning_rate\n",
    "df_results['num_epochs'] = num_epochs\n",
    "df_results['batch_size'] = batch_size\n",
    "df_results['num_classes'] = num_classes\n",
    "df_results['test_size'] = test_size\n",
    "df_results['train_size'] = train_size\n",
    "df_results['seed'] = seed\n",
    "df_results['test_size'] = test_size\n",
    "df_results['train_class_proportion_' + categories[0]] = round(train_class_distribution[0][1], 2)\n",
    "df_results['train_class_proportion_' + categories[1]] = round(train_class_distribution[1][1], 2)\n",
    "df_results['train_class_proportion_' + categories[2]] = round(train_class_distribution[2][1], 2)\n",
    "df_results['test_class_proportion_' + categories[0]] = round(test_class_distribution[0][1], 2)\n",
    "df_results['test_class_proportion_' + categories[1]] = round(test_class_distribution[1][1], 2)\n",
    "df_results['test_class_proportion_' + categories[2]] = round(test_class_distribution[2][1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Step</th>\n",
       "      <th>Loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>test_size</th>\n",
       "      <th>train_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>train_class_proportion_normal</th>\n",
       "      <th>train_class_proportion_offensive</th>\n",
       "      <th>train_class_proportion_hate</th>\n",
       "      <th>test_class_proportion_normal</th>\n",
       "      <th>test_class_proportion_offensive</th>\n",
       "      <th>test_class_proportion_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.977281</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3063</td>\n",
       "      <td>7625</td>\n",
       "      <td>11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.842035</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3063</td>\n",
       "      <td>7625</td>\n",
       "      <td>11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.661018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3063</td>\n",
       "      <td>7625</td>\n",
       "      <td>11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.685303</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3063</td>\n",
       "      <td>7625</td>\n",
       "      <td>11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.562943</td>\n",
       "      <td>0.001</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>3063</td>\n",
       "      <td>7625</td>\n",
       "      <td>11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Epoch  Step      Loss  learning_rate  num_epochs  batch_size  num_classes  \\\n",
       "0      1    10  0.977281          0.001           8          32            3   \n",
       "1      1    20  0.842035          0.001           8          32            3   \n",
       "2      1    30  0.661018          0.001           8          32            3   \n",
       "3      1    40  0.685303          0.001           8          32            3   \n",
       "4      1    50  0.562943          0.001           8          32            3   \n",
       "\n",
       "   test_size  train_size  seed  train_class_proportion_normal  \\\n",
       "0       3063        7625    11                           0.86   \n",
       "1       3063        7625    11                           0.86   \n",
       "2       3063        7625    11                           0.86   \n",
       "3       3063        7625    11                           0.86   \n",
       "4       3063        7625    11                           0.86   \n",
       "\n",
       "   train_class_proportion_offensive  train_class_proportion_hate  \\\n",
       "0                               0.1                         0.04   \n",
       "1                               0.1                         0.04   \n",
       "2                               0.1                         0.04   \n",
       "3                               0.1                         0.04   \n",
       "4                               0.1                         0.04   \n",
       "\n",
       "   test_class_proportion_normal  test_class_proportion_offensive  \\\n",
       "0                          0.81                             0.19   \n",
       "1                          0.81                             0.19   \n",
       "2                          0.81                             0.19   \n",
       "3                          0.81                             0.19   \n",
       "4                          0.81                             0.19   \n",
       "\n",
       "   test_class_proportion_hate  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(df, ax, title):\n",
    "    df.groupby('Epoch').Loss.plot(kind='line', legend=True, title=title, ax=ax, figsize=(15,8))\n",
    "    ax.legend(loc='upper right')\n",
    "    plt.xlabel('Step') \n",
    "    plt.ylabel('Loss')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Loss Word Embeddings, Twitter Dataset'}, xlabel='Step', ylabel='Loss'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,1)\n",
    "plot_loss(df_results, axs, title='Loss Word Embeddings, Twitter Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avarage Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(path):\n",
    "    name = path.split('.')[0]\n",
    "    df = pd.read_csv(path)\n",
    "    df['movie_name'] = name\n",
    "    df = df.rename(columns={'Unnamed: 0': 'label'})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathes = ['TheWolfofWallStreet.csv', 'South_Park.csv', 'Pulp_Fiction.csv', 'Django_Unchained.csv', 'AmerricanHistoryX.csv', 'BlacKkKlansman.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for path in pathes:\n",
    "    df = load_df(path)\n",
    "    dataframes.append(df)\n",
    "result_df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>0.927231</td>\n",
       "      <td>0.986553</td>\n",
       "      <td>0.955972</td>\n",
       "      <td>2454.000000</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offensive</td>\n",
       "      <td>0.923445</td>\n",
       "      <td>0.660959</td>\n",
       "      <td>0.770459</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.923355</td>\n",
       "      <td>0.923355</td>\n",
       "      <td>0.923355</td>\n",
       "      <td>0.923355</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.616892</td>\n",
       "      <td>0.549170</td>\n",
       "      <td>0.575477</td>\n",
       "      <td>3040.000000</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  precision    recall  f1-score      support           movie_name\n",
       "0     normal   0.927231  0.986553  0.955972  2454.000000  TheWolfofWallStreet\n",
       "1  offensive   0.923445  0.660959  0.770459   584.000000  TheWolfofWallStreet\n",
       "2       hate   0.000000  0.000000  0.000000     2.000000  TheWolfofWallStreet\n",
       "3   accuracy   0.923355  0.923355  0.923355     0.923355  TheWolfofWallStreet\n",
       "4  macro avg   0.616892  0.549170  0.575477  3040.000000  TheWolfofWallStreet"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## macro avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df.label=='macro avg'].groupby('movie_name')['f1-score'].mean().values.mean().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9042221354763885"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[result_df.label=='accuracy'].precision.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_precision_recall_f1(category):\n",
    "    precision = result_df[result_df.label==category].precision.mean()\n",
    "    recall = result_df[result_df.label==category].recall.mean()\n",
    "    f1 = result_df[result_df.label==category]['f1-score'].mean()\n",
    "    macro_avg = result_df[result_df.label==category]['f1-score'].mean()\n",
    "    \n",
    "    return {'label': category, 'precision': precision, 'recall': recall, 'f1': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dict = get_precision_recall_f1('normal')\n",
    "offensive_dict = get_precision_recall_f1('offensive')\n",
    "hate_dict = get_precision_recall_f1('hate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame([normal_dict, offensive_dict, hate_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>0.928156</td>\n",
       "      <td>0.971211</td>\n",
       "      <td>0.949039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offensive</td>\n",
       "      <td>0.652766</td>\n",
       "      <td>0.560201</td>\n",
       "      <td>0.591007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hate</td>\n",
       "      <td>0.564356</td>\n",
       "      <td>0.280216</td>\n",
       "      <td>0.372885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  precision    recall        f1\n",
       "0     normal   0.928156  0.971211  0.949039\n",
       "1  offensive   0.652766  0.560201  0.591007\n",
       "2       hate   0.564356  0.280216  0.372885"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
