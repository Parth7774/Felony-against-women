{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a woman you shouldn't complain about cleani...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boy dats cold...tyga dwn bad for cuffin dat ho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dawg  : You ever fuck a bitch and she start to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>she look like a tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The shit you hear about me might be true or it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  As a woman you shouldn't complain about cleani...      0\n",
       "1  boy dats cold...tyga dwn bad for cuffin dat ho...      1\n",
       "2  Dawg  : You ever fuck a bitch and she start to...      1\n",
       "3                             she look like a tranny      1\n",
       "4  The shit you hear about me might be true or it...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"E:\\github\\movie_hatespeech_detection\\data\\twitter\\twitter.csv\"\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df = df.rename(columns={'class': 'label'})\n",
    "# df['label'] = df['label'].replace({0: 2, 2: 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.775049\n",
       "0    0.167498\n",
       "2    0.057453\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    24472\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset='tweet').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\github\\movie_hatespeech_detection\\data\\movies_for_training\\all_movies.csv'\n",
    "movie_data = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmericanHistoryX(1998)_1</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>Derek.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmericanHistoryX(1998)_2</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>1</td>\n",
       "      <td>What the fuck are you thinking?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmericanHistoryX(1998)_3</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a black guy outside breaking into your...</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmericanHistoryX(1998)_4</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>How long has he been there?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmericanHistoryX(1998)_5</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_id    batch_id  majority_answer  \\\n",
       "0  AmericanHistoryX(1998)_1  1566624979                0   \n",
       "1  AmericanHistoryX(1998)_2  1566624979                1   \n",
       "2  AmericanHistoryX(1998)_3  1566624979                0   \n",
       "3  AmericanHistoryX(1998)_4  1566624979                0   \n",
       "4  AmericanHistoryX(1998)_5  1566624979                0   \n",
       "\n",
       "                                                text         movie_name  \n",
       "0                                             Derek.  AmerricanHistoryX  \n",
       "1                    What the fuck are you thinking?  AmerricanHistoryX  \n",
       "2  There's a black guy outside breaking into your...  AmerricanHistoryX  \n",
       "3                        How long has he been there?  AmerricanHistoryX  \n",
       "4                                      I don't know.  AmerricanHistoryX  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    18967\n",
      "0     4099\n",
      "2     1406\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:ylabel='label'>], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.label.value_counts())\n",
    "df.label.value_counts().plot(kind='pie', subplots=True, autopct='%1.0f%%', title='Hate Speech Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, seed, test_size):\n",
    "    train, test = train_test_split(df, test_size=test_size, random_state=seed, shuffle=True)\n",
    "    return train.tweet.values, train.label.values, test.tweet.values, test.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0,1,2]\n",
    "seed = 11\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets, test, test_targets = split_dataset(df, seed=seed, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = len(train)\n",
    "test_size = len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_class_distribution(targets, categories):\n",
    "    df = pd.DataFrame({'category':targets})\n",
    "    s = df.category.value_counts(normalize=True)\n",
    "    s = s.reindex(categories)\n",
    "    return [s.index[0], s[0]], [s.index[1], s[1]], [s.index[2], s[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0.16779894774480258], [1, 0.7750421412882464], [2, 0.05715891096695101])\n",
      "([0, 0.1662921348314607], [1, 0.7750766087844739], [2, 0.05863125638406537])\n"
     ]
    }
   ],
   "source": [
    "train_class_distribution = calculate_dataset_class_distribution(train_targets, categories)\n",
    "test_class_distribution = calculate_dataset_class_distribution(test_targets, categories)\n",
    "print(train_class_distribution)\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Bunch(data=train, target=train_targets)\n",
    "test_ds = Bunch(data=test, target=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the vocabularies and indexing to a unique position\n",
    "vocab = Counter()\n",
    "#Indexing words from the training data\n",
    "for text in train_ds.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "#Indexing words from the training data\n",
    "for text in test_ds.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "for text in movie_data.text.values:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "\n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38658\n",
      "96\n",
      "38658\n"
     ]
    }
   ],
   "source": [
    "print(len(word2index))\n",
    "print(word2index[\"the\"]) # Showing the index of 'the'\n",
    "print (total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "class News_20_Net(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(News_20_Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True).cuda()\n",
    "        self.relu = nn.ReLU().cuda()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True).cuda()\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True).cuda()\n",
    "    # accept input and return an output\n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(df,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    # Split into different batchs, get the next batch \n",
    "    texts = df.data[i*batch_size:i*batch_size+batch_size]\n",
    "    # get the targets \n",
    "    categories = df.target[i*batch_size:i*batch_size+batch_size]\n",
    "    #print(categories)\n",
    "    for text in texts:\n",
    "        # Dimension, 196609\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "        batches.append(layer)\n",
    "\n",
    "    # We have 5 categories\n",
    "    for category in categories:\n",
    "        #print(category)\n",
    "        index_y = -1\n",
    "        if category == 0:\n",
    "            index_y = 0\n",
    "        elif category == 1:\n",
    "            index_y = 1\n",
    "        elif category == 2:\n",
    "            index_y = 2\n",
    "        results.append(index_y)\n",
    "\n",
    "    # the training and the targets\n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 8\n",
    "batch_size = 32\n",
    "display_step = 10 # ADDED will multiplied by 10\n",
    "\n",
    "# Network Parameters\n",
    "hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "input_size = total_words # Words in vocab\n",
    "num_classes = len(categories)         # Categories: \"graphics\",\"space\",\"baseball\",\"guns\", \"christian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 1, 'Step': 100, 'Loss': 0.5339282751083374}\n",
      "{'Epoch': 1, 'Step': 200, 'Loss': 0.6157453656196594}\n",
      "{'Epoch': 1, 'Step': 300, 'Loss': 0.4290543794631958}\n",
      "{'Epoch': 1, 'Step': 400, 'Loss': 0.20704731345176697}\n",
      "{'Epoch': 1, 'Step': 500, 'Loss': 0.2698601484298706}\n",
      "{'Epoch': 1, 'Step': 600, 'Loss': 0.3692278265953064}\n",
      "{'Epoch': 2, 'Step': 100, 'Loss': 0.333543062210083}\n",
      "{'Epoch': 2, 'Step': 200, 'Loss': 0.26942670345306396}\n",
      "{'Epoch': 2, 'Step': 300, 'Loss': 0.26908552646636963}\n",
      "{'Epoch': 2, 'Step': 400, 'Loss': 0.11285869032144547}\n",
      "{'Epoch': 2, 'Step': 500, 'Loss': 0.1551561802625656}\n",
      "{'Epoch': 2, 'Step': 600, 'Loss': 0.07202954590320587}\n",
      "{'Epoch': 3, 'Step': 100, 'Loss': 0.1383640021085739}\n",
      "{'Epoch': 3, 'Step': 200, 'Loss': 0.11787940561771393}\n",
      "{'Epoch': 3, 'Step': 300, 'Loss': 0.21497097611427307}\n",
      "{'Epoch': 3, 'Step': 400, 'Loss': 0.038727086037397385}\n",
      "{'Epoch': 3, 'Step': 500, 'Loss': 0.054312046617269516}\n",
      "{'Epoch': 3, 'Step': 600, 'Loss': 0.01229896117001772}\n",
      "{'Epoch': 4, 'Step': 100, 'Loss': 0.028822816908359528}\n",
      "{'Epoch': 4, 'Step': 200, 'Loss': 0.04586130380630493}\n",
      "{'Epoch': 4, 'Step': 300, 'Loss': 0.15123747289180756}\n",
      "{'Epoch': 4, 'Step': 400, 'Loss': 0.02239672839641571}\n",
      "{'Epoch': 4, 'Step': 500, 'Loss': 0.03748912736773491}\n",
      "{'Epoch': 4, 'Step': 600, 'Loss': 0.00983547791838646}\n",
      "{'Epoch': 5, 'Step': 100, 'Loss': 0.007894915528595448}\n",
      "{'Epoch': 5, 'Step': 200, 'Loss': 0.0019509706180542707}\n",
      "{'Epoch': 5, 'Step': 300, 'Loss': 0.0635039433836937}\n",
      "{'Epoch': 5, 'Step': 400, 'Loss': 0.010024133138358593}\n",
      "{'Epoch': 5, 'Step': 500, 'Loss': 0.022966554388403893}\n",
      "{'Epoch': 5, 'Step': 600, 'Loss': 0.006124798208475113}\n",
      "{'Epoch': 6, 'Step': 100, 'Loss': 0.0018023266457021236}\n",
      "{'Epoch': 6, 'Step': 200, 'Loss': 0.0005651363171637058}\n",
      "{'Epoch': 6, 'Step': 300, 'Loss': 0.03057892993092537}\n",
      "{'Epoch': 6, 'Step': 400, 'Loss': 0.0032001505605876446}\n",
      "{'Epoch': 6, 'Step': 500, 'Loss': 0.007129755336791277}\n",
      "{'Epoch': 6, 'Step': 600, 'Loss': 0.001199800055474043}\n",
      "{'Epoch': 7, 'Step': 100, 'Loss': 0.001086150063201785}\n",
      "{'Epoch': 7, 'Step': 200, 'Loss': 0.0005745152593590319}\n",
      "{'Epoch': 7, 'Step': 300, 'Loss': 0.014027111232280731}\n",
      "{'Epoch': 7, 'Step': 400, 'Loss': 0.0023550456389784813}\n",
      "{'Epoch': 7, 'Step': 500, 'Loss': 0.00642203725874424}\n",
      "{'Epoch': 7, 'Step': 600, 'Loss': 0.0006682535167783499}\n",
      "{'Epoch': 8, 'Step': 100, 'Loss': 0.0002869010204449296}\n",
      "{'Epoch': 8, 'Step': 200, 'Loss': 0.0004616265941876918}\n",
      "{'Epoch': 8, 'Step': 300, 'Loss': 0.00920383632183075}\n",
      "{'Epoch': 8, 'Step': 400, 'Loss': 0.0010248454054817557}\n",
      "{'Epoch': 8, 'Step': 500, 'Loss': 0.0017727544764056802}\n",
      "{'Epoch': 8, 'Step': 600, 'Loss': 0.0006188273546285927}\n"
     ]
    }
   ],
   "source": [
    "news_net = News_20_Net(input_size, hidden_size, num_classes)\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # This includes the Softmax loss function\n",
    "optimizer = torch.optim.Adam(news_net.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    # determine the number of min-batches based on the batch size and size of training data\n",
    "    total_batch = int(len(train_ds.data)/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_ds,i,batch_size)\n",
    "        \n",
    "        articles = torch.cuda.FloatTensor(batch_x, device='cuda')\n",
    "        labels = torch.cuda.LongTensor(batch_y, device='cuda')\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = news_net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % display_step == 0:\n",
    "            result = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f'%(epoch+1, num_epochs, i+1, len(train_ds.data)/batch_size, loss.data)\n",
    "            results.append({'Epoch': epoch+1, 'Step': i+1, 'Loss': loss.data.item()})\n",
    "            if (i+1) % (display_step*10) == 0:\n",
    "                print({'Epoch': epoch+1, 'Step': i+1, 'Loss': loss.data.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_test_data = len(test_ds.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterates = total_test_data/batch_size # ignore last (<batch_size) batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total = []\n",
    "all_correct = []\n",
    "labels_all = []\n",
    "predicted_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(iterates)):\n",
    "    batch_x_test,batch_y_test = get_batch(test_ds,i,batch_size)\n",
    "    articles = torch.FloatTensor(batch_x_test).to('cuda')\n",
    "    labels = torch.LongTensor(batch_y_test).to('cuda')\n",
    "    outputs = news_net(articles)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    labels_all.extend([x.item() for x in labels])\n",
    "    predicted_all.extend([x.item() for x in predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(labels_all, predicted_all, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.78</td>\n",
       "      <td>808.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>3773.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.26</td>\n",
       "      <td>283.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.66</td>\n",
       "      <td>4864.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4864.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "0                  0.79    0.78      0.78   808.00\n",
       "1                  0.90    0.95      0.93  3773.00\n",
       "2                  0.43    0.18      0.26   283.00\n",
       "accuracy           0.87    0.87      0.87     0.87\n",
       "macro avg          0.71    0.64      0.66  4864.00\n",
       "weighted avg       0.86    0.87      0.86  4864.00"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classication of Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_df(movie_df):\n",
    "    utterances = movie_df.text.values\n",
    "    predictions = []\n",
    "    batch = []\n",
    "    \n",
    "    for text in utterances:\n",
    "        # Dimension, 196609\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "\n",
    "        batch.append(layer)\n",
    "        \n",
    "    texts = torch.FloatTensor(batch).to('cuda')\n",
    "    outputs = news_net(texts)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.extend([x.item() for x in predicted])\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        result.append({'index': i, 'label_bow_twitter': pred})\n",
    "    \n",
    "    result_df = pd.DataFrame(result)\n",
    "    movie_df = movie_df.merge(result_df, right_index=True, left_index=True)\n",
    "    \n",
    "    return movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = annotate_df(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.label_bow_twitter.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5951\n",
       "0    4267\n",
       "2     470\n",
       "Name: label_bow_twitter, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.label_bow_twitter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9014\n",
       "1    1380\n",
       "2     294\n",
       "Name: majority_answer, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.majority_answer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifications_results(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    labels_all = df.majority_answer.values\n",
    "    predicted_all = df.label_bow_twitter.values\n",
    "    \n",
    "    results_classification = classification_report(labels_all, predicted_all, output_dict=True)\n",
    "    \n",
    "    df_report = pd.DataFrame(results_classification).transpose()\n",
    "    \n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>9014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1380.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>294.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.36</td>\n",
       "      <td>10688.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.83</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>10688.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score   support\n",
       "0                  0.95    0.45      0.61   9014.00\n",
       "1                  0.19    0.83      0.31   1380.00\n",
       "2                  0.12    0.19      0.15    294.00\n",
       "accuracy           0.49    0.49      0.49      0.49\n",
       "macro avg          0.42    0.49      0.36  10688.00\n",
       "weighted avg       0.83    0.49      0.56  10688.00"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classifications_results(result_df).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
