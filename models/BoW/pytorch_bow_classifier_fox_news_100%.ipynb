{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>True. Most leftists ,esp female leftists have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>First, lets get this straight</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>White privilege ...work all your life to take ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>I love you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>I hate you</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment  label\n",
       "1510  True. Most leftists ,esp female leftists have ...      1\n",
       "1511                      First, lets get this straight      1\n",
       "1512  White privilege ...work all your life to take ...      1\n",
       "1513                                         I love you      0\n",
       "1514                                         I hate you      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"E:\\github\\movie_hatespeech_detection\\data\\fox_news\\fox_news.csv\"\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df = df.rename(columns={'class': 'label'})\n",
    "df['label'] = df['label'].replace({2:1})\n",
    "df = df.append({'comment': 'I love you', 'label': 0}, ignore_index=True)\n",
    "df = df.append({'comment': 'I hate you', 'label': 1}, ignore_index=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'E:\\github\\movie_hatespeech_detection\\data\\movies_for_training\\all_movies.csv'\n",
    "movie_data = pd.read_csv(path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmericanHistoryX(1998)_1</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>Derek.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmericanHistoryX(1998)_2</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>1</td>\n",
       "      <td>What the fuck are you thinking?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmericanHistoryX(1998)_3</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a black guy outside breaking into your...</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmericanHistoryX(1998)_4</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>How long has he been there?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmericanHistoryX(1998)_5</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   movie_id    batch_id  majority_answer  \\\n",
       "0  AmericanHistoryX(1998)_1  1566624979                0   \n",
       "1  AmericanHistoryX(1998)_2  1566624979                1   \n",
       "2  AmericanHistoryX(1998)_3  1566624979                0   \n",
       "3  AmericanHistoryX(1998)_4  1566624979                0   \n",
       "4  AmericanHistoryX(1998)_5  1566624979                0   \n",
       "\n",
       "                                                text         movie_name  \n",
       "0                                             Derek.  AmerricanHistoryX  \n",
       "1                    What the fuck are you thinking?  AmerricanHistoryX  \n",
       "2  There's a black guy outside breaking into your...  AmerricanHistoryX  \n",
       "3                        How long has he been there?  AmerricanHistoryX  \n",
       "4                                      I don't know.  AmerricanHistoryX  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1084\n",
      "1     431\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([<AxesSubplot:ylabel='label'>], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.label.value_counts())\n",
    "df.label.value_counts().plot(kind='pie', subplots=True, autopct='%1.0f%%', title='Hate Speech Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, seed):\n",
    "    df = df.copy()\n",
    "    test = df.loc[1513:1514]\n",
    "    df.drop(df.tail(1).index, inplace=True)\n",
    "    train = df.sample(frac=1, random_state=seed)\n",
    "    return train.comment.values, train.label.values, test.comment, test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [0,1]\n",
    "seed = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_targets, test, test_targets = split_dataset(df, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1514\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train)\n",
    "test_size = len(test)\n",
    "print(train_size)\n",
    "print(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_class_distribution(targets, categories):\n",
    "    df = pd.DataFrame({'category':targets})\n",
    "    s = df.category.value_counts(normalize=True)\n",
    "    s = s.reindex(categories)\n",
    "    return [s.index[0], s[0]], [s.index[1], s[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0.7159841479524438], [1, 0.28401585204755614])\n",
      "([0, 0.5], [1, 0.5])\n"
     ]
    }
   ],
   "source": [
    "train_class_distribution = calculate_dataset_class_distribution(train_targets, categories)\n",
    "test_class_distribution = calculate_dataset_class_distribution(test_targets, categories)\n",
    "print(train_class_distribution)\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Bunch(data=train, target=train_targets)\n",
    "test_ds = Bunch(data=test, target=test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all the vocabularies and indexing to a unique position\n",
    "vocab = Counter()\n",
    "#Indexing words from the training data\n",
    "for text in train_ds.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "#Indexing words from the training data\n",
    "for text in test_ds.data:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "\n",
    "for text in movie_data.text.values:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()]+=1\n",
    "        \n",
    "total_words = len(vocab)\n",
    "\n",
    "def get_word_2_index(vocab):\n",
    "    word2index = {}\n",
    "    for i,word in enumerate(vocab):\n",
    "        word2index[word.lower()] = i\n",
    "\n",
    "    return word2index\n",
    "\n",
    "word2index = get_word_2_index(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17732\n",
      "13\n",
      "17732\n"
     ]
    }
   ],
   "source": [
    "print(len(word2index))\n",
    "print(word2index[\"the\"]) # Showing the index of 'the'\n",
    "print (total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the network\n",
    "class News_20_Net(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(News_20_Net, self).__init__()\n",
    "        self.layer_1 = nn.Linear(input_size,hidden_size, bias=True).cuda()\n",
    "        self.relu = nn.ReLU().cuda()\n",
    "        self.layer_2 = nn.Linear(hidden_size, hidden_size, bias=True).cuda()\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes, bias=True).cuda()\n",
    "    # accept input and return an output\n",
    "     def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(df,i,batch_size):\n",
    "    batches = []\n",
    "    results = []\n",
    "    # Split into different batchs, get the next batch \n",
    "    texts = df.data[i*batch_size:i*batch_size+batch_size]\n",
    "    # get the targets \n",
    "    categories = df.target[i*batch_size:i*batch_size+batch_size]\n",
    "    #print(categories)\n",
    "    for text in texts:\n",
    "        # Dimension, 196609\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "        batches.append(layer)\n",
    "\n",
    "    # We have 5 categories\n",
    "    for category in categories:\n",
    "        #print(category)\n",
    "        index_y = -1\n",
    "        if category == 0:\n",
    "            index_y = 0\n",
    "        elif category == 1:\n",
    "            index_y = 1\n",
    "        elif category == 2:\n",
    "            index_y = 2\n",
    "        results.append(index_y)\n",
    "\n",
    "    # the training and the targets\n",
    "    return np.array(batches),np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 8\n",
    "batch_size = 32\n",
    "display_step = 1 # ADDED will multiplied by 10\n",
    "\n",
    "# Network Parameters\n",
    "hidden_size = 100      # 1st layer and 2nd layer number of features\n",
    "input_size = total_words # Words in vocab\n",
    "num_classes = len(categories)         # Categories: \"graphics\",\"space\",\"baseball\",\"guns\", \"christian\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 1, 'Step': 10, 'Loss': 0.6423895359039307}\n",
      "{'Epoch': 1, 'Step': 20, 'Loss': 0.5471791625022888}\n",
      "{'Epoch': 1, 'Step': 30, 'Loss': 0.6262851357460022}\n",
      "{'Epoch': 1, 'Step': 40, 'Loss': 0.5675703287124634}\n",
      "{'Epoch': 2, 'Step': 10, 'Loss': 0.44184085726737976}\n",
      "{'Epoch': 2, 'Step': 20, 'Loss': 0.30666372179985046}\n",
      "{'Epoch': 2, 'Step': 30, 'Loss': 0.40755540132522583}\n",
      "{'Epoch': 2, 'Step': 40, 'Loss': 0.2627961039543152}\n",
      "{'Epoch': 3, 'Step': 10, 'Loss': 0.14209066331386566}\n",
      "{'Epoch': 3, 'Step': 20, 'Loss': 0.09308931976556778}\n",
      "{'Epoch': 3, 'Step': 30, 'Loss': 0.21916751563549042}\n",
      "{'Epoch': 3, 'Step': 40, 'Loss': 0.018723975867033005}\n",
      "{'Epoch': 4, 'Step': 10, 'Loss': 0.026511583477258682}\n",
      "{'Epoch': 4, 'Step': 20, 'Loss': 0.0300114918500185}\n",
      "{'Epoch': 4, 'Step': 30, 'Loss': 0.04757861793041229}\n",
      "{'Epoch': 4, 'Step': 40, 'Loss': 0.0020073177292943}\n",
      "{'Epoch': 5, 'Step': 10, 'Loss': 0.009803763590753078}\n",
      "{'Epoch': 5, 'Step': 20, 'Loss': 0.010308003053069115}\n",
      "{'Epoch': 5, 'Step': 30, 'Loss': 0.01612784154713154}\n",
      "{'Epoch': 5, 'Step': 40, 'Loss': 0.0006806100136600435}\n",
      "{'Epoch': 6, 'Step': 10, 'Loss': 0.002340278821066022}\n",
      "{'Epoch': 6, 'Step': 20, 'Loss': 0.004538328852504492}\n",
      "{'Epoch': 6, 'Step': 30, 'Loss': 0.006500729359686375}\n",
      "{'Epoch': 6, 'Step': 40, 'Loss': 0.0004955026088282466}\n",
      "{'Epoch': 7, 'Step': 10, 'Loss': 0.0013542778324335814}\n",
      "{'Epoch': 7, 'Step': 20, 'Loss': 0.002491510007530451}\n",
      "{'Epoch': 7, 'Step': 30, 'Loss': 0.0035716816782951355}\n",
      "{'Epoch': 7, 'Step': 40, 'Loss': 0.00022489992261398584}\n",
      "{'Epoch': 8, 'Step': 10, 'Loss': 0.0008802241063676775}\n",
      "{'Epoch': 8, 'Step': 20, 'Loss': 0.001600845018401742}\n",
      "{'Epoch': 8, 'Step': 30, 'Loss': 0.002211217535659671}\n",
      "{'Epoch': 8, 'Step': 40, 'Loss': 0.00014365706010721624}\n"
     ]
    }
   ],
   "source": [
    "news_net = News_20_Net(input_size, hidden_size, num_classes)\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # This includes the Softmax loss function\n",
    "optimizer = torch.optim.Adam(news_net.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    # determine the number of min-batches based on the batch size and size of training data\n",
    "    total_batch = int(len(train_ds.data)/batch_size)\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x,batch_y = get_batch(train_ds,i,batch_size)\n",
    "        \n",
    "        articles = torch.cuda.FloatTensor(batch_x, device='cuda')\n",
    "        labels = torch.cuda.LongTensor(batch_y, device='cuda')\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = news_net(articles)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % display_step == 0:\n",
    "            result = 'Epoch [%d/%d], Step [%d/%d], Loss: %.4f'%(epoch+1, num_epochs, i+1, len(train_ds.data)/batch_size, loss.data)\n",
    "            results.append({'Epoch': epoch+1, 'Step': i+1, 'Loss': loss.data.item()})\n",
    "            if (i+1) % (display_step*10) == 0:\n",
    "                print({'Epoch': epoch+1, 'Step': i+1, 'Loss': loss.data.item()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "total_test_data = len(test_ds.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterates = total_test_data/batch_size # ignore last (<batch_size) batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_total = []\n",
    "all_correct = []\n",
    "labels_all = []\n",
    "predicted_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(iterates)):\n",
    "    batch_x_test,batch_y_test = get_batch(test_ds,i,batch_size)\n",
    "    \n",
    "    articles = torch.FloatTensor(batch_x_test).to('cuda')\n",
    "    \n",
    "    labels = torch.LongTensor(batch_y_test).to('cuda')\n",
    "    outputs = news_net(articles)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    labels_all.extend([x.item() for x in labels])\n",
    "    predicted_all.extend([x.item() for x in predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niklas\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Niklas\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Niklas\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\Niklas\\AppData\\Roaming\\Python\\Python38\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(labels_all, predicted_all, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score  support\n",
       "accuracy            0.0     0.0       0.0      0.0\n",
       "macro avg           NaN     NaN       NaN      0.0\n",
       "weighted avg        0.0     0.0       0.0      0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_report.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classication of Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_df(movie_df):\n",
    "    utterances = movie_df.text.values\n",
    "    predictions = []\n",
    "    batch = []\n",
    "    \n",
    "    for text in utterances:\n",
    "        # Dimension, 196609\n",
    "        layer = np.zeros(total_words,dtype=float)\n",
    "\n",
    "        for word in text.split(' '):\n",
    "            layer[word2index[word.lower()]] += 1\n",
    "\n",
    "        batch.append(layer)\n",
    "        \n",
    "    texts = torch.FloatTensor(batch).to('cuda')\n",
    "    outputs = news_net(texts)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    predictions.extend([x.item() for x in predicted])\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for i, pred in enumerate(predictions):\n",
    "        result.append({'index': i, 'label_bow_fox_news': pred})\n",
    "    \n",
    "    result_df = pd.DataFrame(result)\n",
    "    movie_df = movie_df.merge(result_df, right_index=True, left_index=True)\n",
    "    \n",
    "    return movie_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = annotate_df(movie_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_for_sana = result_df[['text', 'label_bow_fox_news']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>majority_answer</th>\n",
       "      <th>text</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>index</th>\n",
       "      <th>label_bow_fox_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmericanHistoryX(1998)_1</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>Derek.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmericanHistoryX(1998)_2</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>1</td>\n",
       "      <td>What the fuck are you thinking?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmericanHistoryX(1998)_3</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>There's a black guy outside breaking into your...</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AmericanHistoryX(1998)_4</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>How long has he been there?</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AmericanHistoryX(1998)_5</td>\n",
       "      <td>1566624979</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>AmerricanHistoryX</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10683</th>\n",
       "      <td>TheWolfofWallStreet2013BluRay_3724</td>\n",
       "      <td>3859903933</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell me this pen.</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "      <td>10683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10684</th>\n",
       "      <td>TheWolfofWallStreet2013BluRay_3725</td>\n",
       "      <td>3859903933</td>\n",
       "      <td>0</td>\n",
       "      <td>Well, it's a nice pen.</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "      <td>10684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10685</th>\n",
       "      <td>TheWolfofWallStreet2013BluRay_3726_3727</td>\n",
       "      <td>3859903933</td>\n",
       "      <td>0</td>\n",
       "      <td>You can use the pen to write down thoughts fro...</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "      <td>10685</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10686</th>\n",
       "      <td>TheWolfofWallStreet2013BluRay_3728</td>\n",
       "      <td>3859903933</td>\n",
       "      <td>0</td>\n",
       "      <td>Sell me this pen.</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "      <td>10686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10687</th>\n",
       "      <td>TheWolfofWallStreet2013BluRay_3729_3730</td>\n",
       "      <td>3859903933</td>\n",
       "      <td>0</td>\n",
       "      <td>Well... This pen works and I personally love t...</td>\n",
       "      <td>TheWolfofWallStreet</td>\n",
       "      <td>10687</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10688 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      movie_id    batch_id  majority_answer  \\\n",
       "0                     AmericanHistoryX(1998)_1  1566624979                0   \n",
       "1                     AmericanHistoryX(1998)_2  1566624979                1   \n",
       "2                     AmericanHistoryX(1998)_3  1566624979                0   \n",
       "3                     AmericanHistoryX(1998)_4  1566624979                0   \n",
       "4                     AmericanHistoryX(1998)_5  1566624979                0   \n",
       "...                                        ...         ...              ...   \n",
       "10683       TheWolfofWallStreet2013BluRay_3724  3859903933                0   \n",
       "10684       TheWolfofWallStreet2013BluRay_3725  3859903933                0   \n",
       "10685  TheWolfofWallStreet2013BluRay_3726_3727  3859903933                0   \n",
       "10686       TheWolfofWallStreet2013BluRay_3728  3859903933                0   \n",
       "10687  TheWolfofWallStreet2013BluRay_3729_3730  3859903933                0   \n",
       "\n",
       "                                                    text           movie_name  \\\n",
       "0                                                 Derek.    AmerricanHistoryX   \n",
       "1                        What the fuck are you thinking?    AmerricanHistoryX   \n",
       "2      There's a black guy outside breaking into your...    AmerricanHistoryX   \n",
       "3                            How long has he been there?    AmerricanHistoryX   \n",
       "4                                          I don't know.    AmerricanHistoryX   \n",
       "...                                                  ...                  ...   \n",
       "10683                                  Sell me this pen.  TheWolfofWallStreet   \n",
       "10684                             Well, it's a nice pen.  TheWolfofWallStreet   \n",
       "10685  You can use the pen to write down thoughts fro...  TheWolfofWallStreet   \n",
       "10686                                  Sell me this pen.  TheWolfofWallStreet   \n",
       "10687  Well... This pen works and I personally love t...  TheWolfofWallStreet   \n",
       "\n",
       "       index  label_bow_fox_news  \n",
       "0          0                   0  \n",
       "1          1                   0  \n",
       "2          2                   0  \n",
       "3          3                   0  \n",
       "4          4                   0  \n",
       "...      ...                 ...  \n",
       "10683  10683                   0  \n",
       "10684  10684                   0  \n",
       "10685  10685                   0  \n",
       "10686  10686                   0  \n",
       "10687  10687                   0  \n",
       "\n",
       "[10688 rows x 7 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9334\n",
       "1    1354\n",
       "Name: label_bow_fox_news, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.label_bow_fox_news.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9014\n",
       "1    1380\n",
       "2     294\n",
       "Name: majority_answer, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.majority_answer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classifications_results(df):\n",
    "    \n",
    "    df['majority_answer'] = df['majority_answer'].replace({2:1})\n",
    "    \n",
    "    labels_all = df.majority_answer.values\n",
    "    predicted_all = df.label_bow_fox_news.values\n",
    "\n",
    "    results_classification = classification_report(labels_all, predicted_all, output_dict=True)\n",
    "    \n",
    "    df_report = pd.DataFrame(results_classification).transpose()\n",
    "    \n",
    "    return df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.86</td>\n",
       "      <td>9014.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1674.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>10688.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10688.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision  recall  f1-score   support\n",
       "0                  0.84    0.87      0.86   9014.00\n",
       "1                  0.16    0.13      0.14   1674.00\n",
       "accuracy           0.76    0.76      0.76      0.76\n",
       "macro avg          0.50    0.50      0.50  10688.00\n",
       "weighted avg       0.74    0.76      0.75  10688.00"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_classifications_results(result_df).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
